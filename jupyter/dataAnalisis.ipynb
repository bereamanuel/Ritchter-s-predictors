{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nepal earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Manuel Berea Arellano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 0: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Drivendata] competition: \n",
    "\n",
    "Richter's Predictor: Modeling Earthquake Damage  https://www.drivendata.org/competitions/57/nepal-earthquake/page/134/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        DATA\n",
    "# ==================== #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "#      PLOTING\n",
    "# ============================== #\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#      CLUSTERING\n",
    "# ============================== #\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "#      PRE PROCESSING\n",
    "# ============================== #\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#      METRICS\n",
    "# ============================== #\n",
    "from sklearn.metrics import f1_score   # average='micro'\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#      MODEL SELECTION\n",
    "# ============================== #\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "#      CLASIFICATORS\n",
    "# ============================== #\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#      OTHERS\n",
    "# ============================== #\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "\n",
    "#      WARNINGS\n",
    "# ============================== #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')\n",
    "#dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplots_algorithms(results, names):\n",
    "    \"\"\" \n",
    "    For plot the results\n",
    "    \n",
    "    Para plotear los resultados \n",
    "    Input\n",
    "    --------\n",
    "    results (Pandas DF): Results of training models\n",
    "    names: Names of the models\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Image in the notebook\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.boxplot(results)\n",
    "    plt.xticks(range(1,len(names)+1), names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_reshape(img):\n",
    "    \"\"\"\n",
    "    For show a image.\n",
    "    Para mostrar una imagen.\n",
    "\n",
    "    Input\n",
    "    --------\n",
    "    img (String): path image\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Image in the notebook\n",
    "\n",
    "    \"\"\"\n",
    "    img = Image.open('./images/'+img).convert('RGB')\n",
    "    img = img.resize((300,500))\n",
    "    img = np.asarray(img)\n",
    "    return img\n",
    "\n",
    "def img_reshape_more(img):\n",
    "    \"\"\"\n",
    "    For show a image.\n",
    "    Para mostrar una imagen.\n",
    "\n",
    "    Input\n",
    "    --------\n",
    "    img (String): path image\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Image in the notebook\n",
    "\n",
    "    \"\"\"\n",
    "    img = Image.open('./images/'+img).convert('RGB')\n",
    "    img = img.resize((1000,500))\n",
    "    img = np.asarray(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities(df, test, n): \n",
    "    \"\"\"\n",
    "    Calculate probabilities for distinc geo level and target groups.\n",
    "    Calcular las probabilidades para los distintos geo level y grupos de la target.\n",
    "\n",
    "    Input\n",
    "    --------\n",
    "    df (DataFrame pandas)\n",
    "    n (Int): values 1,2,3 for distinct geo level\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Dataframe with probabilities new columns\n",
    "    \n",
    "    \"\"\"\n",
    "    column = [f\"geo_level_{n}_id\"]\n",
    "    nom1 = [f\"prob1_geo{n}\"]\n",
    "    nom2 = [f\"prob2_geo{n}\"]\n",
    "    nom3 = [f\"prob3_geo{n}\"]\n",
    "    #This will save the probabilities in one column for each in df and dfOut\n",
    "    damage1 = dict()\n",
    "    damage2 = dict()\n",
    "    damage3 = dict()\n",
    "\n",
    "    for i, j in df[column].value_counts().iteritems():\n",
    "        n1 = len(df[df.damage_grade == 1][df[column[0]] == i])\n",
    "        n2 = len(df[df.damage_grade == 2][df[column[0]] == i])\n",
    "        n3 = len(df[df.damage_grade == 3][df[column[0]] == i])\n",
    "\n",
    "        damage1[i[0]] = n1/j\n",
    "        damage2[i[0]] = n2/j\n",
    "        damage3[i[0]] = n3/j\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "\n",
    "    for i in df[column[0]]:\n",
    "        list1.append(damage1.get(i))\n",
    "        list2.append(damage2.get(i))\n",
    "        list3.append(damage3.get(i))\n",
    "\n",
    "    df[nom1[0]] = list1\n",
    "    df[nom2[0]] = list2\n",
    "    df[nom3[0]] = list3\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "\n",
    "    for i in test[column[0]]:\n",
    "        list1.append(damage1.get(i))\n",
    "        list2.append(damage2.get(i))\n",
    "        list3.append(damage3.get(i))\n",
    "\n",
    "    test[nom1[0]] = list1\n",
    "    test[nom2[0]] = list2\n",
    "    test[nom3[0]] = list3\n",
    "    \n",
    "    return df , test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "A model is trained using  of the folds as training data;\n",
    "\n",
    "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. \n",
    "\n",
    "Extratree classifier is a type of Random forest Classifier, the diference is the randomness goes one step further in the war splits are computed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the performance of our algorithms, we'll use the F1 score which balances the precision and recall of a classifier. Traditionally, the F1 score is used to evaluate performance on a binary classifier, but since we have three possible labels we will use a variant called the micro averaged F1 score. \n",
    "\n",
    "$$ F_{micro} = \\frac{ 2 \\cdot P_{micro} \\cdot R_{micro} }{P_{micro} + R_{micro}} $$\n",
    "\n",
    "where \n",
    "$$ P_{micro} = \\frac{\\sum TP_k}{\\sum (TP_k + FP_k)}, \\ with \\ k=1,2,3 $$\n",
    "and\n",
    "$$ R_{micro} = \\frac{\\sum TP_k}{\\sum (TP_k + FN_k)}, \\ with \\ k=1,2,3 $$\n",
    "\n",
    "$TP$ is true positive, $FP$ is False positive, $FN$ is False negative.\n",
    "\n",
    "In python, you can use f_score with average ='micro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out-of-bag error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-bag (OOB) error, also called out-of-bag estimate, is a method of measuring the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging). Bagging uses subsampling with replacement to create training samples for the model to learn from. OOB error is the mean prediction error on each training sample xi, using only the trees that did not have xi in their bootstrap sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset mainly consists of information on the buildings' structure and their legal ownership. Each row in the dataset represents a specific building in the region that was hit by Gorkha earthquake.\n",
    "\n",
    "*----*\n",
    "\n",
    "\n",
    "El conjunto de datos principalmente consiste en la información estuctural de los datos y su propietario legal. Cada fila del conjunto de datos representa un edificio concreto en la region donde tuvo lugar el terremoto Gorkha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_values.csv\")\n",
    "trainTar = pd.read_csv(\"../data/train_labels.csv\")\n",
    "\n",
    "test = pd.read_csv(\"../data/test_values.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge on one dataframe because it'll permit a better analysis. For feature engineering, we'll merge test to.\n",
    "\n",
    "*----*\n",
    "\n",
    "Unimos en un solo dataframe ya que nos permite un mejor analisis de la target. Para las distintas transformaciones también tendremos que unir el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.merge(trainTar , on= \"building_id\" , how= \"left\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {} rows and {} columns \\n  -Categorical: 8 \\n  -Binary: 22 \\n  -Integer: 6 \".format(len(df) , len(df.columns)))\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Tenemos {} filas y {} columns \\n  -Categoricas: 8 \\n  -Binarias: 22 \\n  -Enetero: 6 \".format(len(df) , len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} rows duplicated\".format(len(df) - df.duplicated().value_counts().values[0]))\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Hay {} filas duplicadas\".format(len(df) - df.duplicated().value_counts().values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} nan values\".format(df.isna().sum().sum()))\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Hay {} valores nulos\".format(df.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not nan values, but we should see if there are wrong values\n",
    "\n",
    "*-----*\n",
    "\n",
    "No hay valores nulos, pero deberíamos mirar si hay errores en algún valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We select only the int columns\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Seleccionamos solo las columnas con dato entero\")\n",
    "df[[\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 0 and 995 value for age column, this is a error value. 0 is it posible but 995 is strange.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vemos como hay valor 0 y 995 en la columna edad, eso es un valor erroneo. 0 es posible, pero 995 es un valor extraño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data = df, y =\"age\" , x=\"damage_grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With boxplot we see that very well. If we won't use robust scaler, we should drop outliers. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Con el boxplot lo podemos ver muy bien. Si no vamos a usar robust scaler, debemos borrar los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df, x =\"age\" , kind= \"count\" ,  aspect=4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(df[df['age']==995])} values with value 995, i.e {round( 100*len(df[df['age']==995]) / len(df) ,2)} % of total, these probably are unknown values.\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(f\"Hay {len(df[df['age']==995])} valores con 995, i.e {round( 100*len(df[df['age']==995]) / len(df) ,2)} % the total, son probablemente valores desconocidos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the distribution:\n",
    "\n",
    "*-----*\n",
    "\n",
    "Aquí podemos ver la distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['age']==995].groupby(['damage_grade']).count()['building_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop outliers, but in other hand we analize the age in groups and we'll see what is better.\n",
    "It seems that would nice make groups with the age, because there are a lot of outliers, and we can make groups to solve this problem.\n",
    "\n",
    "We'll do this in the next chapter.\n",
    "\n",
    "*----*\n",
    "\n",
    "Vamos a borrar los outliers, pero por otro lado vamos a analizar la edad en grupos y veremos cual es mejor.\n",
    "Parece optimo hacer grupos de edad de los edificiones, porque hay muchos outliers y podemos hacer grupos para resolver este problema.\n",
    "\n",
    "Heremos esto en el proximo capítulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_1 = df.describe().loc['25%'].loc['age']\n",
    "Q_3 = df.describe().loc['75%'].loc['age']\n",
    "IQR = Q_3 - Q_1\n",
    "df['outliers'] = df['age'].apply( lambda x : 1 if ((x < (Q_1 - 1.5*IQR) ) or ( (Q_3 + 1.5 * IQR) < x ) ) else 0 )\n",
    "print(f\"There are {df['outliers'].sum()} outliers, i.e {round( 100*df['outliers'].sum() / len(df) , 2 )} % of total, we are going to drop it\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(f\"Hay {df['outliers'].sum()} outliers, es un {round( 100*df['outliers'].sum() / len(df) , 2 )} % del total, vamos a sacarlos del estudio\")\n",
    "dfOut = df[df['outliers'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data = dfOut, y =\"age\" , x=\"damage_grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = dfOut, x =\"age\" , kind= \"count\" ,  aspect=4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOut[[\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to see \"area_percentage\" and \"height_percentage\", because it seems like there are outliers too.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vamos a ver la columna \"area_percentage\" y \"height_percentage\", porque parece que también tiene outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfOut[[\"area_percentage\", \"height_percentage\"]].describe())\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "fig.suptitle(\"Area and Height percentage boxplot\")\n",
    "#-----#\n",
    "ax1.set_title(\"Area percentage\")\n",
    "ax1.boxplot(dfOut[[\"area_percentage\"]])\n",
    "#-----#\n",
    "ax2.set_title(\"Hight percentage\")\n",
    "ax2.boxplot(dfOut[[\"height_percentage\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these columns, probably the best idea is use a robust scaler, because 100% value is posible and don't seems an unknown value.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Para estas columns, probablemente la mejor idea es usar un robust scaler, porque el valor 100% es posible y no parece un valor desconocido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before outliers analysis we have:\n",
    "\n",
    "*------*\n",
    "\n",
    "Después del analisis de outliers tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We drop outlierns, now we have {round (100 - len(dfOut)*100 / len(df) ,2)} % less rows than the initial dataframe.\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(f\"Hemos borrado outliers, ahora tenemos un {round (100 - len(dfOut)*100 / len(df) ,2)} % menos filas que el dataframe original.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrTot = df[numeric].corr()\n",
    "corrOut = dfOut[numeric].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the diferences between corrTot and corrOut\n",
    "\n",
    "*-----*\n",
    "\n",
    "Aqui vemos las diferencias entra ambas correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(corrTot-corrOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to analize only the corrTot, because the diferences are minimun.\n",
    "\n",
    "*------*\n",
    "\n",
    "Vamos a analizar la correlacion solo de corrTot, porque las diferencias son mínimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORPLOT\n",
    "plt.figure(figsize=(8, 9))\n",
    "maskTot = np.triu(np.ones_like(corrTot, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corrTot, mask=maskTot, cmap=cmap, vmax=.3, center=0, annot= True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .8} )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest correlation is between number floors pre earthquake and the porcent height. But 0.77 is not enought for drop the column.\n",
    "\n",
    "*------*\n",
    "\n",
    "La correlación más alta es entre numero de plantas antes del terremoto y el porcentaje de altura. Pero 0.77 no es suficiente para borrar la columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Featuring Engineering and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['land_surface_condition','foundation_type','roof_type','ground_floor_type','other_floor_type','position','plan_configuration','legal_ownership_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Land surface condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface condition of the land where the building was built. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Estado de la superficio del terreno donde se contruyó el edificio.\n",
    "\n",
    "\n",
    "Possible values: n, o, t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[0]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[0] , bins=len(set(df[categorical[0]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[0], bins=len(set(df[categorical[0]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[0] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this to analisis, we are going to group the o and n values in one.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Con este analisis, vamos a agrupar los valores o y n en solo uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[0]] = df[categorical[0]].apply(lambda x: 1 if x == 't' else 0)\n",
    "dfOut[categorical[0]] = dfOut[categorical[0]].apply(lambda x: 1 if x == 't' else 0)\n",
    "\n",
    "test[categorical[0]] = test[categorical[0]].apply(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[0] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Foundation type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of foundation used while building. \n",
    "\n",
    "*----*\n",
    "\n",
    "Tipo de financiacion usada cuando se contruyó el edificio.\n",
    "\n",
    "Possible values: h, i, r, u, w.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[1]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[1] , bins=len(set(df[categorical[1]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[1], bins=len(set(df[categorical[1]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[1] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[1]] = df[categorical[1]].apply(lambda x : 1 if x == 'r' else 0)\n",
    "dfOut[categorical[1]] = dfOut[categorical[1]].apply(lambda x : 1 if x == 'r' else 0)\n",
    "\n",
    "test[categorical[1]] = test[categorical[1]].apply(lambda x : 1 if x == 'r' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[1] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roof type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of roof used while building. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Tipo de tejado empleado al construir el edificio\n",
    "\n",
    "Possible values: n, q, x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[2]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[2] , bins=len(set(df[categorical[2]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[2], bins=len(set(df[categorical[2]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[2] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[2]] = df[categorical[2]].apply(lambda x : 1 if x == 'q' else 0)\n",
    "dfOut[categorical[2]] = dfOut[categorical[2]].apply(lambda x : 1 if x == 'q' else 0)\n",
    "\n",
    "test[categorical[2]] = test[categorical[2]].apply(lambda x : 1 if x == 'q' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[2] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ground floor type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of the ground floor. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Tipo de suelo.\n",
    "\n",
    "Possible values: f, m, v, x, z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[3]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[3] , bins=len(set(df[categorical[3]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[3], bins=len(set(df[categorical[3]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[3]] = df[categorical[3]].apply(lambda x : 'other' if x == 'z' else 'other' if x == 'm' else x)\n",
    "dfOut[categorical[3]] = dfOut[categorical[3]].apply(lambda x : 'other' if x == 'z' else 'other' if x == 'm' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[3]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "sns.catplot(data= df , x = categorical[3] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[3]] = df[categorical[3]].apply(lambda x : 1 if x == 'f' else 0)\n",
    "dfOut[categorical[3]] = dfOut[categorical[3]].apply(lambda x : 1 if x == 'f' else 0)\n",
    "\n",
    "test[categorical[3]] = test[categorical[3]].apply(lambda x : 1 if x == 'f' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[3] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other floor type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Type of constructions used in higher than the ground floors (except of roof). \n",
    " \n",
    " *-----*\n",
    "\n",
    " Tipo de materiales usados en plantas superiores distintas a la baja y techo.\n",
    " \n",
    " Possible values: j, q, s, x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[4]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[4] , bins=len(set(df[categorical[4]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[4], bins=len(set(df[categorical[4]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[4] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[4]] = df[categorical[4]].apply(lambda x : 'j' if x == 's' else x)\n",
    "dfOut[categorical[4]] = dfOut[categorical[4]].apply(lambda x : 'j' if x == 's' else x)\n",
    "\n",
    "test[categorical[4]] = test[categorical[4]].apply(lambda x : 'j' if x == 's' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[4]] = df[categorical[4]].apply(lambda x : 2 if x == 'q' else 1 if x == 'x' else  0)\n",
    "dfOut[categorical[4]] = dfOut[categorical[4]].apply(lambda x : 2 if x == 'q' else 1 if x == 'x' else  0)\n",
    "\n",
    "test[categorical[4]] = test[categorical[4]].apply(lambda x : 2 if x == 'q' else 1 if x == 'x' else  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[4] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position of the building. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Posición del edificio.\n",
    "\n",
    "Possible values: j, o, s, t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[5]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[5] , bins=len(set(df[categorical[5]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[5], bins=len(set(df[categorical[5]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[5] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[5]] = df[categorical[5]].apply(lambda x : 1 if x == 's' else 0)\n",
    "dfOut[categorical[5]] = dfOut[categorical[5]].apply(lambda x : 1 if x == 's' else 0)\n",
    "\n",
    "test[categorical[5]] = test[categorical[5]].apply(lambda x : 1 if x == 's' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[5] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plan configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building plan configuration. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Configuración del plano del edificio.\n",
    "\n",
    "Possible values: a, c, d, f, m, n, o, q, s, u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[6]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[6] , bins=len(set(df[categorical[6]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[6], bins=len(set(df[categorical[6]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[6] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[6]] = df[categorical[6]].apply(lambda x : 1 if x == 'd' else 0)\n",
    "dfOut[categorical[6]] = dfOut[categorical[6]].apply(lambda x : 1 if x == 'd' else 0)\n",
    "\n",
    "test[categorical[6]] = test[categorical[6]].apply(lambda x : 1 if x == 'd' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[6] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column is not well clustered, we are going to drop it\n",
    "\n",
    "*----*\n",
    "\n",
    "Esta columna no está bien repartida, vamos a eliminarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(categorical[6], axis = 1)\n",
    "dfOut = dfOut.drop(categorical[6], axis = 1)\n",
    "\n",
    "test = test.drop(categorical[6], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Legal ownership status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal ownership status of the land where building was built. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Situación de la propiedad legal del terreno donde se construyó el edificio. \n",
    "\n",
    "\n",
    "Possible values: a, r, v, w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[7]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[7] , bins=len(set(df[categorical[7]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[7], bins=len(set(df[categorical[7]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(categorical[7], axis = 1)\n",
    "dfOut = dfOut.drop(categorical[7], axis = 1)\n",
    "\n",
    "test = test.drop(categorical[7], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). \n",
    "\n",
    "\n",
    "*-----*\n",
    "\n",
    "\n",
    "Region geográfica en donde hay edificios, del más grande (level 1) al mas especifico, sub region (level 3).\n",
    "\n",
    "Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2]:\n",
    "    print(\"\\n- - - - - - - \")\n",
    "    with pd.option_context('display.max_rows',10):\n",
    "        print(df[geos[i]].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the probability of belonging to one target group or another based on the geo level columns. This will help us to cluster the diferent positions.\n",
    "\n",
    "*-------*\n",
    "\n",
    "Vamos a calcular la probabilidad de pertenecer a un grupo de la target u otro en función de las columnas de geo level. Esto nos ayudará a relacionar las distintas posiciones y clusterizarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, test = probabilities(df,test,1)\n",
    "df, test = probabilities(df,test,2)\n",
    "df, test = probabilities(df,test,3)\n",
    "\n",
    "#df.to_csv(\"../data/trainProb.csv\")\n",
    "#test.to_csv(\"../data/testProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOut, testOut = probabilities(dfOut,test,1)\n",
    "dfOut, testOut = probabilities(dfOut,test,2)\n",
    "dfOut, testOut = probabilities(dfOut,test,3)\n",
    "\n",
    "#dfOut.to_csv(\"../data/trainOutProb.csv\")\n",
    "#testOut.to_csv(\"../data/testOutProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "#test = pd.read_csv(\"../data/testProb.csv\")\n",
    "\n",
    "#dfOut = pd.read_csv(\"../data/trainOutProb.csv\")\n",
    "#testOut = pd.read_csv(\"../data/testOutProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = ['prob1_geo1','prob2_geo1', 'prob3_geo1', 'prob1_geo2', 'prob2_geo2', 'prob3_geo2','prob1_geo3', 'prob2_geo3', 'prob3_geo3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClus = range(3, 10)\n",
    "kmeans = [KMeans(n_clusters=i, random_state= 1995) for i in nClus]\n",
    "\n",
    "score = [kmeans[i].fit(df[probs]).score(df[probs]) for i in range(len(kmeans))]\n",
    "\n",
    "plt.plot(nClus,score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seen the plot, I'll choose 5 clusters.\n",
    "\n",
    "*-------*\n",
    "\n",
    "Viendo el gráfico, voy a escoger 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5 , random_state = 1995 )\n",
    "kmeans.fit(df[probs])\n",
    "\n",
    "# Predicting the clusters\n",
    "labels = kmeans.predict(df[probs])\n",
    "labelsT = kmeans.predict(test[probs])\n",
    "\n",
    "df['clusters'] = labels\n",
    "test['clusters'] = labelsT\n",
    "\n",
    "# *-----*\n",
    "\n",
    "kmeans = KMeans(n_clusters = 5 , random_state = 1995 )\n",
    "kmeans.fit(dfOut[probs])\n",
    "\n",
    "# Predicting the clusters\n",
    "labels = kmeans.predict(dfOut[probs])\n",
    "labelsT = kmeans.predict(testOut[probs])\n",
    "\n",
    "dfOut['clusters'] = labels\n",
    "testOut['clusters'] = labelsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = \"clusters\" , kind=\"count\" , hue= \"damage_grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to analize the binary columns.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Finalmente vamos a analizar las columnas de valor binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = ['has_secondary_use','has_secondary_use_agriculture','has_secondary_use_gov_office','has_secondary_use_health_post',\n",
    "            'has_secondary_use_hotel','has_secondary_use_industry','has_secondary_use_institution','has_secondary_use_other',\n",
    "            'has_secondary_use_rental','has_secondary_use_school','has_secondary_use_use_police','has_superstructure_adobe_mud',\n",
    "            'has_superstructure_bamboo','has_superstructure_cement_mortar_brick','has_superstructure_cement_mortar_stone', \n",
    "            'has_superstructure_mud_mortar_brick', 'has_superstructure_mud_mortar_stone', 'has_superstructure_other', \n",
    "            'has_superstructure_rc_engineered','has_superstructure_rc_non_engineered', 'has_superstructure_stone_flag', 'has_superstructure_timber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\t% of 1 in the columns\")\n",
    "print(\"\\t- - - - - - - - - - - - - - - - - - - \")\n",
    "print(\"\\t\\t% de 1 en las columnas\")\n",
    "round(df[binary].sum() *100 / len(df) , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = list()\n",
    "for x in binary:\n",
    "    if (round(df[x].sum() *100 / len(df) , 2) < 10.0) == True:\n",
    "        dp.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = df.drop(dp, axis=1)\n",
    "dfOut_mod = dfOut.drop(dp, axis=1)\n",
    "test_mod = test.drop(dp, axis=1)\n",
    "testOut_mod = testOut.drop(dp, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model, we'll use:\n",
    "\n",
    "*------*\n",
    "\n",
    "Para el primer modelo, vamos a usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count floors pre earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of floors in the building before the earthquake.\n",
    "\n",
    "*------*\n",
    "\n",
    "Numero de plantas del edificio pre terremoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[0] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric[0]] = df[numeric[0]].apply(lambda x: x if x<3 else 3)\n",
    "dfOut[numeric[0]] = dfOut[numeric[0]].apply(lambda x: x if x<3 else 3)\n",
    "test[numeric[0]] = test[numeric[0]].apply(lambda x: x if x<3 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[0] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age of the building in years.\n",
    "\n",
    "*------*\n",
    "\n",
    "Edad del edificio en años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = dfOut , x = numeric[1] , kind= 'count', hue='damage_grade', height=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOut[numeric[1]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs robust scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized area and height of the building footprint.\n",
    "\n",
    "*------*\n",
    "\n",
    "Superficie y altura normalizadas de la huella del edificio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Families"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of families that live in the building.\n",
    "\n",
    "*-------*\n",
    "\n",
    "Numero de familias que viven en el edificio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[4] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric[4]] = df[numeric[4]].apply(lambda x: x if x<2 else 2)\n",
    "dfOut[numeric[4]] = dfOut[numeric[4]].apply(lambda x: x if x<2 else 2)\n",
    "test[numeric[4]] = test[numeric[4]].apply(lambda x: x if x<2 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[4] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First models: Evaluating and comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'damage_grade'\n",
    "numeric = [ \"age\" ,'prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "categorical = ['clusters','roof_type',\"area_percentage\" , \"height_percentage\",\"count_floors_pre_eq\", \"count_families\",'foundation_type','ground_floor_type','has_secondary_use','has_superstructure_mud_mortar_stone','has_superstructure_timber','land_surface_condition','other_floor_type','position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_mod.columns) - set([target]) - set(numeric) - set(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escaler = RobustScaler().fit(df[numeric])\n",
    "escalerOut = RobustScaler().fit(dfOut[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric] = escaler.transform(df[numeric])\n",
    "test[numeric] = escaler.transform(test[numeric])\n",
    "\n",
    "dfOut[numeric] = escalerOut.transform(dfOut[numeric])\n",
    "testOut[numeric] = escalerOut.transform(testOut[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = [target,'outliers']), df[target],random_state = 1995)\n",
    "X_trainO, X_testO, y_trainO, y_testO = train_test_split(dfOut.drop(columns = [target,'outliers']), dfOut[target],random_state = 1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare distinct models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compare the distinct type of classifiers for select the better options and for each selected model do hyperparameter tunning.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vamos a comparar los distintos tipos de clasificadores para seleccionar la mejor option y para cada uno de estos hacer el tuneado de los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1995\n",
    "models = []\n",
    "models.append(('LR'     , LogisticRegression(random_state=seed)))\n",
    "models.append(('LDA'    , LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN'    , KNeighborsClassifier()))\n",
    "models.append(('DTC'    , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('NB'     , GaussianNB()))\n",
    "models.append(('RFC'    , RandomForestClassifier(random_state=seed)))\n",
    "models.append(('EXT'    , ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('LGBM'   , LGBMClassifier(random_state=seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "metric = 'f1_micro'\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    cv_results = cross_val_score(model, X_trainO, y_trainO, cv =5, scoring = metric)\n",
    "\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "boxplots_algorithms(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1995\n",
    "models = []\n",
    "models.append(('LDA'    , LinearDiscriminantAnalysis()))\n",
    "models.append(('RFC'    , RandomForestClassifier(random_state=seed)))\n",
    "models.append(('EXT'    , ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('LGBM'   , LGBMClassifier(random_state=seed)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "metric = 'f1_micro'\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    cv_results = cross_val_score(model, X_trainO, y_trainO, cv =5, scoring = metric)\n",
    "\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "boxplots_algorithms(results, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear discriminant analysis is the most easy way to explain the models. We can get the coefs and with this coefs explain the predictions.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Analisis discriminantes es la forma más fácil de explicar modelos. Ya que nos devuelve los distintos coeficientes que nos ayudan a explicar las prediccioes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'solver' : ['svd', 'lsqr', 'eigen'] \n",
    "}\n",
    "\n",
    "CVLRmodel = LinearDiscriminantAnalysis()\n",
    "\n",
    "gridLDA = GridSearchCV( estimator = CVLRmodel,\n",
    "                        param_grid = param,\n",
    "                        scoring = 'f1_micro',\n",
    "                        n_jobs = -1,\n",
    "                        refit = True,\n",
    "                        cv = 5,\n",
    "                        verbose = 1,\n",
    "                        return_train_score = True)\n",
    "\n",
    "gridLDA.fit(X_trainO,y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionesLDA = gridLDA.predict(X = X_testO)\n",
    "\n",
    "f1score0 = f1_score(\n",
    "        y_true  = y_testO,\n",
    "        y_pred  = prediccionesLDA,\n",
    "        average = 'micro'\n",
    "    )\n",
    "\n",
    "print(f\"El f1 score de test es: {round(f1score0,3)} con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = testOut.copy()\n",
    "\n",
    "prediccionesLDA = gridLDA.predict(test_copy)\n",
    "test_copy['damage_grade'] = prediccionesLDA\n",
    "test_copy[['building_id','damage_grade']].to_csv(\"../predictions/predLDAmodel1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took 0.7203 score in drivenData platform. Now we have try with the other models.\n",
    "\n",
    "*----*\n",
    "\n",
    "Obtuve 0.7203 de score en la plataforma de drivenData. Ahora vamos a probar con otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = RandomForestClassifier(\n",
    "            n_estimators = 150,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 'auto',\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)\n",
    "\n",
    "\n",
    "modeloOut = RandomForestClassifier(\n",
    "            n_estimators = 150,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 'auto',\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(X_train, y_train) , modeloOut.fit(X_trainO, y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo inicial\n",
    "# ==============================================================================\n",
    "predicciones = modelo.predict(X = X_test)\n",
    "\n",
    "f1score1 = f1_score(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        average = 'micro'\n",
    "       )\n",
    "print(f\"El f1 score de test es: {round(f1score1,3)} con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.copy()\n",
    "testOut1 = testOut.copy()\n",
    "\n",
    "\n",
    "predicciones = modelo.predict(test1)\n",
    "test['damage_grade'] = predicciones\n",
    "test[['building_id','damage_grade']].to_csv(\"../predictions/predETCmodel1.csv\", index = False)\n",
    "\n",
    "\n",
    "prediccionesOut = modeloOut.predict(testOut1)\n",
    "testOut['damage_grade'] = prediccionesOut\n",
    "testOut[['building_id','damage_grade']].to_csv(\"../predictions/predOutETCmodel1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a first point to improve. The next steps are:\n",
    "    \n",
    "    - Tunning the model\n",
    "  \n",
    "    - Compare with other algorithms\n",
    "  \n",
    "    - Improve our featuring engineering, for exmple, changing the clustering.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model with outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/one.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/oneOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tunning: Num estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a loop for training the diferent models with each n_estimador value and take train error and Out-of Bag value. It'll permit us choose the best parameter option for our dataframe.\n",
    "It's important choose the less number of trees with the best score, more trees wont improve our power prediction but it will make us don't have the best performance.\n",
    "\n",
    "*------*\n",
    "\n",
    "Vamos a utilizar un bucle para entrenar los diferentes moderlos con cada uno de los valores de los estimadores y cogeremos el error y el valor Out.of-bag. Esto nos va a permitir elegir la mejor opcion de parámetros para nuestro conjunto de datos. Es importante elegir el menor número de árboles con el mayor score, más arboles no implica mayor poder predictivo, pero si que hará empeorar nuestro performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "oob_scores   = []\n",
    "\n",
    "estimator_range = range(1, 200, 25)\n",
    "\n",
    "# Loop for training models with each n_estimator value and take\n",
    "# train error and Out-of-Bag value.\n",
    "for n_estimators in estimator_range:\n",
    "    model = ExtraTreesClassifier(\n",
    "                n_estimators = n_estimators,\n",
    "                criterion    = 'gini',\n",
    "                max_depth    = 10,\n",
    "                max_features = 'auto',\n",
    "                bootstrap    = True,\n",
    "                oob_score    = True,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 1995\n",
    "             )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    train_scores.append(model.score(X_train, y_train))\n",
    "    oob_scores.append(model.oob_score_)\n",
    "    \n",
    "# Graph for analize the error\n",
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "ax.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "ax.plot(estimator_range, oob_scores, label=\"out-of-bag scores\")\n",
    "ax.plot(estimator_range[np.argmax(oob_scores)], max(oob_scores),\n",
    "        marker='o', color = \"red\", label=\"max score\")\n",
    "ax.set_xlabel(\"n_estimators\")\n",
    "ax.set_title(\"Evolution out-of-bag-error vs num estimators\")\n",
    "plt.legend();\n",
    "print(f\"Best value of n_estimators: {estimator_range[np.argmax(oob_scores)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use cross validation with f1 score. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Ahora vamos a utilizar cross validation con la métrica f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV validation\n",
    "# ==============================================================================\n",
    "estimator_range = range(1, 100, 20)\n",
    "cv_scores = []\n",
    "for n_estimators in estimator_range:\n",
    "    \n",
    "    modelo = ExtraTreesClassifier(\n",
    "                n_estimators = n_estimators,\n",
    "                criterion    = 'gini',\n",
    "                max_depth    = 10,\n",
    "                max_features = 'auto',\n",
    "                bootstrap    = True,\n",
    "                oob_score    = True,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 1995\n",
    "             )\n",
    "    scores = cross_val_score(\n",
    "                estimator = modelo,\n",
    "                X         = X_train,\n",
    "                y         = y_train,\n",
    "                scoring   = 'f1_micro',\n",
    "                cv        = 5\n",
    "             )   \n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "print(f\"Best value of n_estimators: {estimator_range[np.argmax(cv_scores)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should take around 50 and 60 trees.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Debemos coger entre 50 y 60 árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tunning: Max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV validation\n",
    "# ==============================================================================\n",
    "max_features_range = range(1, X_train.shape[1] + 1, 1)\n",
    "cv_scores = []\n",
    "for max_features in max_features_range:\n",
    "    \n",
    "    modelo = ExtraTreesClassifier(\n",
    "                n_estimators = 55,\n",
    "                criterion    = 'gini',\n",
    "                max_depth    = 10,\n",
    "                max_features = max_features,\n",
    "                bootstrap    = True,\n",
    "                oob_score    = True,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 1995\n",
    "             )\n",
    "    scores = cross_val_score(\n",
    "                estimator = modelo,\n",
    "                X         = X_train,\n",
    "                y         = y_train,\n",
    "                scoring   = 'f1_micro',\n",
    "                cv        = 5\n",
    "             )   \n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "    \n",
    "print(f\"Best value of n_estimators: {max_features_range[np.argmax(cv_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSte = ExtraTreesClassifier(\n",
    "            n_estimators = 55,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 46,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)\n",
    "\n",
    "\n",
    "modeloSteOut = ExtraTreesClassifier(\n",
    "            n_estimators = 55,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 46,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSte.fit(X_train, y_train) , modeloSteOut.fit(X_trainO, y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo inicial\n",
    "# ==============================================================================\n",
    "predicciones = modeloSte.predict(X = X_test)\n",
    "\n",
    "f1score1 = f1_score(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        average = 'micro'\n",
    "       )\n",
    "print(f\"El f1 score de test es: {f1score1} con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.copy()\n",
    "testOut1 = testOut.copy()\n",
    "\n",
    "predicciones = modeloSte.predict(test1)\n",
    "test['damage_grade'] = predicciones\n",
    "test[['building_id','damage_grade']].to_csv(\"../predictions/predETCmodel2.csv\", index = False)\n",
    "\n",
    "\n",
    "prediccionesOut = modeloSteOut.predict(testOut1)\n",
    "testOut['damage_grade'] = prediccionesOut\n",
    "testOut[['building_id','damage_grade']].to_csv(\"../predictions/predOutETCmodel2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/twoOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tunning: Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "# ==============================================================================\n",
    "param_grid = {'n_estimators': [50,55,60],\n",
    "              'max_features': [46,None],\n",
    "              'max_depth'   : [None, 3,5,10],\n",
    "              'criterion'   : ['gini']\n",
    "             }\n",
    "\n",
    "# Grid serach CV \n",
    "# ==============================================================================\n",
    "gridRF = GridSearchCV(\n",
    "        estimator  = ExtraTreesClassifier(random_state = 1995),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_micro',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1995), \n",
    "        refit      = True,\n",
    "        verbose    = 1,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridRF.fit(X = X_trainO, y = y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloHyperOut = ExtraTreesClassifier(\n",
    "            n_estimators = 50,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 46,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloHyperOut.fit(X_trainO,y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut2 = testOut.drop(\"damage_grade\",axis=1).copy()\n",
    "\n",
    "prediccionesOut = modeloHyperOut.predict(testOut2)\n",
    "testOut2['damage_grade'] = prediccionesOut\n",
    "testOut2[['building_id','damage_grade']].to_csv(\"../predictions/predOutETCmodel3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/threeOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: LightGBM Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Num estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "f1_scores   = []\n",
    "estimator_range = range(25, 500, 25)\n",
    "# Loop for training models with each n_estimator value and take\n",
    "# train error and f1 score\n",
    "for n_estimators in estimator_range:\n",
    "    model = LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_estimators= n_estimators, \n",
    "                    n_jobs =-1, \n",
    "                    num_leaves=124, \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995)\n",
    "\n",
    "    model.fit(X_trainO, y_trainO)\n",
    "    train_scores.append(model.score(X_trainO, y_trainO))\n",
    "    \n",
    "    predicciones = model.predict(X = X_testO)\n",
    "\n",
    "    f1score1 = f1_score(\n",
    "            y_true  = y_testO,\n",
    "            y_pred  = predicciones,\n",
    "            average = 'micro'\n",
    "        )\n",
    "    f1_scores.append(f1score1)\n",
    "# Graph for analize the error\n",
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "ax.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "ax.plot(estimator_range, f1_scores, label=\"F1 Score\")\n",
    "ax.plot(estimator_range[np.argmax(f1_scores)], max(f1_scores),\n",
    "        marker='o', color = \"red\", label=\"max score\")\n",
    "ax.set_xlabel(\"n_estimators\")\n",
    "ax.set_title(\"Evolution F1 Score vs num estimators\")\n",
    "plt.legend();\n",
    "print(f\"Best value of n_estimators: {estimator_range[np.argmax(f1_scores)]} with f1 score: {max(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try with this num estimators.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vamos a probar con esta cantidad de estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLGBMOut = LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_estimators= 425, \n",
    "                    n_jobs =-1, \n",
    "                    num_leaves=124, \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLGBMOut.fit(X_trainO,y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut3 = testOut.copy()\n",
    "\n",
    "prediccionesOut = modeloLGBMOut.predict(testOut3)\n",
    "testOut3['damage_grade'] = prediccionesOut\n",
    "testOut3[['building_id','damage_grade']].to_csv(\"../predictions/predOutLGBMmodel1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/threeOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Searchgrid CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "# ==============================================================================\n",
    "param_grid = {'n_estimators': [400,425,450],\n",
    "              'num_leaves'  : [10,35,135],\n",
    "              'max_depth'   : [-1,5,10],\n",
    "              'learning_rate':[0.01]\n",
    "             }\n",
    "\n",
    "# Grid serach CV \n",
    "# ==============================================================================\n",
    "gridLGBM = GridSearchCV(\n",
    "        estimator  = LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_jobs =-1,  \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_micro',\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1995), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridLGBM.fit(X = X_trainO, y = y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridLGBM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLGBM =  LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_estimators= 450, \n",
    "                    n_jobs =-1, \n",
    "                    num_leaves=135, \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995)\n",
    "\n",
    "modelLGBM.fit(X_trainO, y_trainO)\n",
    "\n",
    "prediccionesLGBM = modelLGBM.predict(X = X_testO)\n",
    "\n",
    "f1score1 = f1_score(\n",
    "        y_true  = y_testO,\n",
    "        y_pred  = prediccionesLGBM,\n",
    "        average = 'micro'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut4 = testOut.copy()\n",
    "\n",
    "prediccionesLGBM = modelLGBM.predict(testOut4)\n",
    "testOut4['damage_grade'] = prediccionesLGBM\n",
    "testOut4[['building_id','damage_grade']].to_csv(\"../predictions/predOutLGBMmodel2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LGBM hyperparameter tunning\")\n",
    "pred_model1 = img_reshape_more('/prediccions/threeOutLGBMHYPER.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Featuring Engineering and selection (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- log(age) --> Power tranformers (Box-Cox)\n",
    "- Truco cuantiles  ---> CountMinSketch\n",
    "- Cambiar numero de clusters\n",
    "- Utilizar min-max scaler por dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to try a better featuring engineering, improving the transformations.\n",
    "\n",
    "*----*\n",
    "\n",
    "Ahora vamos a tratar de mejorar el featuring engineering, mejorando las transformaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "train = pd.read_csv(\"../data/train_values.csv\")\n",
    "trainTar = pd.read_csv(\"../data/train_labels.csv\")\n",
    "df = train.merge(trainTar , on= \"building_id\" , how= \"left\")\n",
    "\n",
    "#Test\n",
    "test = pd.read_csv(\"../data/test_values.csv\")\n",
    "\n",
    "\n",
    "#Probabilities\n",
    "df, test = probabilities(df,test,1)\n",
    "df, test = probabilities(df,test,2)\n",
    "df, test = probabilities(df,test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint\n",
    "df.to_csv(\"../data/trainProb.csv\", index = False)\n",
    "test.to_csv(\"../data/testProb.csv\", index = False)\n",
    "\n",
    "#df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "#test = pd.read_csv(\"../data/testProb.csv\")\n",
    "\n",
    "target = 'damage_grade'\n",
    "numeric = [ \"age\" ,\"area_percentage\" , \"height_percentage\",'prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "categorical = ['roof_type',\"count_floors_pre_eq\", \"count_families\",'foundation_type','ground_floor_type','has_secondary_use','has_superstructure_mud_mortar_stone','has_superstructure_timber','land_surface_condition','other_floor_type','position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to solve the outliers problem without drop this rows. The steps that I'm going to follow are:\n",
    "- Use power tranformers like (Box-Cox).\n",
    "- Re-category poorly represented groups.\n",
    "- Change kluster number.\n",
    "- Use robust-scaler.\n",
    "  \n",
    "*-----*\n",
    "\n",
    "Vamos a tratar de resolver el problema de los outliers sin eliminar las filas. Los pasos a seguir serán:\n",
    "- Usar power transformer como Box.Cox.\n",
    "- Re-categorizar los grupos mal representados.\n",
    "- Cambiar número de clusters. \n",
    "- Usar robus scaler (o min-max scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_log'] = df['age'].apply(lambda x : 0 if x<=0 else np.log(x))\n",
    "\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "df['age_pt'] = pt.fit_transform(df[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2 , ax3) = plt.subplots(3,1, figsize =(15,12))\n",
    "df['age'].hist(ax=ax1, bins=50)\n",
    "ax1.tick_params(labelsize=10)\n",
    "ax1.set_xlabel('age', fontsize=10)\n",
    "ax1.set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['age_log'].hist(ax=ax2, bins=50)\n",
    "ax2.tick_params(labelsize=10)\n",
    "ax2.set_xlabel('log10(age))', fontsize=10)\n",
    "ax2.set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['age_pt'].hist(ax=ax3, bins=50)\n",
    "ax3.tick_params(labelsize=10)\n",
    "ax3.set_xlabel('PowerTransform(age))', fontsize=10)\n",
    "ax3.set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems better the log transformation, but we can check against a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, (ax1, ax2 , ax3) = plt.subplots(3,1, figsize =(12,8))\n",
    "prob1 = stats.probplot(df['age'], dist=stats.norm, plot=ax1)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_title('Probplot against normal distribution')\n",
    "prob2 = stats.probplot(df['age_log'], dist=stats.norm, plot=ax2)\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_title('Probplot after log transform')\n",
    "prob3 = stats.probplot(df['age_pt'], dist=stats.norm, plot=ax3)\n",
    "ax3.set_xlabel('Theoretical quantiles')\n",
    "ax3.set_title('Probplot after Yeo-Jhonson transform')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing this, I think is better the Yeo-Jhonson transform. I'll use it.\n",
    "\n",
    "*---*\n",
    "\n",
    "Viendo este gráfico, parece mejor el yeo-jhonson transform. Usaré este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "test['age_pt'] = pt.fit_transform(test[['age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area and high percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area_percentage_log'] = df['area_percentage'].apply(lambda x : 0 if x<=0 else np.log(x))\n",
    "\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "df['area_percentage_pt'] = pt.fit_transform(df[['area_percentage']])\n",
    "\n",
    "\n",
    "df['height_percentage_log'] = df['height_percentage'].apply(lambda x : 0 if x<=0 else np.log(x))\n",
    "\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "df['height_percentage_pt'] = pt.fit_transform(df[['height_percentage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2, figsize =(15,12))\n",
    "df['area_percentage'].hist(ax=ax[0,0], bins=50)\n",
    "ax[0,0].tick_params(labelsize=10)\n",
    "ax[0,0].set_xlabel('area %', fontsize=10)\n",
    "ax[0,0].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['height_percentage'].hist(ax=ax[0,1], bins=50)\n",
    "ax[0,1].tick_params(labelsize=10)\n",
    "ax[0,1].set_xlabel('hight %', fontsize=10)\n",
    "ax[0,1].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "df['area_percentage_log'].hist(ax=ax[1,0], bins=50)\n",
    "ax[1,0].tick_params(labelsize=10)\n",
    "ax[1,0].set_xlabel('log10(area %))', fontsize=10)\n",
    "ax[1,0].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "\n",
    "df['height_percentage_log'].hist(ax=ax[1,1], bins=50)\n",
    "ax[1,1].tick_params(labelsize=10)\n",
    "ax[1,1].set_xlabel('log10(hight %))', fontsize=10)\n",
    "ax[1,1].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['area_percentage_pt'].hist(ax=ax[2,0], bins=50)\n",
    "ax[2,0].tick_params(labelsize=10)\n",
    "ax[2,0].set_xlabel('PowerTransform(area %))', fontsize=10)\n",
    "ax[2,0].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "\n",
    "df['height_percentage_pt'].hist(ax=ax[2,1], bins=50)\n",
    "ax[2,1].tick_params(labelsize=10)\n",
    "ax[2,1].set_xlabel('PowerTransform(hight %))', fontsize=10)\n",
    "ax[2,1].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots(3,2, figsize =(15,12))\n",
    "prob1 = stats.probplot(df['area_percentage'], dist=stats.norm, plot=ax[0,0])\n",
    "ax[0,0].set_xlabel('')\n",
    "ax[0,0].set_title('Area Probplot against normal distribution')\n",
    "prob1 = stats.probplot(df['height_percentage'], dist=stats.norm, plot=ax[0,1])\n",
    "ax[0,1].set_xlabel('')\n",
    "ax[0,1].set_title('Height Probplot against normal distribution')\n",
    "\n",
    "\n",
    "prob2 = stats.probplot(df['area_percentage_log'], dist=stats.norm, plot=ax[1,0])\n",
    "ax[1,0].set_xlabel('')\n",
    "ax[1,0].set_title('Area Probplot after log transform')\n",
    "prob2 = stats.probplot(df['height_percentage_log'], dist=stats.norm, plot=ax[1,1])\n",
    "ax[1,1].set_xlabel('')\n",
    "ax[1,1].set_title('Height Probplot after log transform')\n",
    "\n",
    "\n",
    "prob3 = stats.probplot(df['area_percentage_pt'], dist=stats.norm, plot=ax[2,0])\n",
    "ax[2,0].set_xlabel('Theoretical quantiles')\n",
    "ax[2,0].set_title('Area Probplot after Yeo-Jhonson transform')\n",
    "prob3 = stats.probplot(df['height_percentage_pt'], dist=stats.norm, plot=ax[2,1])\n",
    "ax[2,1].set_xlabel('Theoretical quantiles')\n",
    "ax[2,1].set_title('Height Probplot after Yeo-Jhonson transform')\n",
    "\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that yeo-jhonson its better option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "test['area_percentage_pt'] = pt.fit_transform(test[['area_percentage']])\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "test['height_percentage_pt'] = pt.fit_transform(test[['height_percentage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we have more than 5% in all categories, then I will only create dummies and i'll drop the x dummy column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(2,5, figsize =(25,10))\n",
    "ax[0,0].hist(df['count_families'])\n",
    "ax[0,0].set_xlabel('count_families', fontsize=10)\n",
    "\n",
    "ax[0,1].hist(df['count_floors_pre_eq'])\n",
    "ax[0,1].set_xlabel('count_floors_pre_eq', fontsize=10)\n",
    "\n",
    "ax[0,2].hist(df['roof_type'])\n",
    "ax[0,2].set_xlabel('roof_type', fontsize=10)\n",
    "\n",
    "ax[0,3].hist(df['position'])\n",
    "ax[0,3].set_xlabel('position', fontsize=10)\n",
    "\n",
    "ax[1,0].hist(df['foundation_type'])\n",
    "ax[1,0].set_xlabel('foundation_type', fontsize=10)\n",
    "\n",
    "ax[1,1].hist(df['ground_floor_type'])\n",
    "ax[1,1].set_xlabel('ground_floor_type', fontsize=10)\n",
    "\n",
    "ax[1,2].hist(df['land_surface_condition'])\n",
    "ax[1,2].set_xlabel('land_surface_condition', fontsize=10)\n",
    "\n",
    "ax[1,3].hist(df['other_floor_type'])\n",
    "ax[1,3].set_xlabel('other_floor_type', fontsize=10)\n",
    "\n",
    "ax[0,4].hist(df['legal_ownership_status'])\n",
    "ax[0,4].set_xlabel('legal_ownership_status', fontsize=10)\n",
    "\n",
    "ax[1,4].hist(df['plan_configuration'])\n",
    "ax[1,4].set_xlabel('plan_configuration', fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_families'] = df['count_families'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "df['count_floors_pre_eq'] = df['count_floors_pre_eq'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "\n",
    "df['position'] = df['position'].apply(lambda x: 'j' if x == 'o' else x)\n",
    "df['legal_ownership_status'] = df['legal_ownership_status'].apply(lambda x: str(1) if x == 'v' else str(0))\n",
    "\n",
    "df['foundation_type'] = df['foundation_type'].apply(lambda x: str(1) if x == 'r' else str(0))\n",
    "df['ground_floor_type'] = df['ground_floor_type'].apply(lambda x: str(1) if x == 'f' else str(0))\n",
    "\n",
    "df['plan_configuration'] = df['plan_configuration'].apply(lambda x : str(1) if x=='d' else str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['count_families'] = test['count_families'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "test['count_floors_pre_eq'] = test['count_floors_pre_eq'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "\n",
    "test['position'] = test['position'].apply(lambda x: 'j' if x == 'o' else x)\n",
    "test['legal_ownership_status'] = test['legal_ownership_status'].apply(lambda x: str(1) if x == 'v' else str(0))\n",
    "\n",
    "test['foundation_type'] = test['foundation_type'].apply(lambda x: str(1) if x == 'r' else str(0))\n",
    "test['ground_floor_type'] = test['ground_floor_type'].apply(lambda x: str(1) if x == 'f' else str(0))\n",
    "\n",
    "test['plan_configuration'] = test['plan_configuration'].apply(lambda x : str(1) if x=='d' else str(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to solve the outliers problem without drop this rows. The steps that I'm going to follow are:\n",
    "    - Use power tranformers like (Box-Cox).\n",
    "    - Re-category poorly represented groups.\n",
    "    - Change kluster number.\n",
    "    - Use robust-scaler.\n",
    "  \n",
    "*-----*\n",
    "\n",
    "Vamos a tratar de resolver el problema de los outliers sin eliminar las filas. Los pasos a seguir serán:\n",
    "    - Usar power transformer como Box.Cox.\n",
    "    - Re-categorizar los grupos mal representados.\n",
    "    - Cambiar número de clusters. \n",
    "    - Usar robus scaler (o min-max scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'damage_grade' \n",
    "numeric = ['age_pt','area_percentage_pt', 'height_percentage_pt','prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "dummies = ['count_families_0','count_families_1','count_families_2',\n",
    "                'count_floors_pre_eq_1','count_floors_pre_eq_2',\n",
    "                'foundation_type_1', 'ground_floor_type_1',\n",
    "                'land_surface_condition_t','land_surface_condition_n',\n",
    "                'other_floor_type_j','other_floor_type_q', 'other_floor_type_x', \n",
    "                'position_s','position_t',\n",
    "                'roof_type_n','roof_type_q']\n",
    "\n",
    "binary= ['has_secondary_use','has_secondary_use_agriculture','has_secondary_use_gov_office','has_secondary_use_health_post','has_secondary_use_hotel',\n",
    "    'has_secondary_use_industry','has_secondary_use_institution','has_secondary_use_other','has_secondary_use_rental',\n",
    "    'has_secondary_use_school','has_secondary_use_use_police','has_superstructure_adobe_mud','has_superstructure_bamboo','has_superstructure_cement_mortar_brick',\n",
    "    'has_superstructure_cement_mortar_stone','has_superstructure_mud_mortar_brick','has_superstructure_mud_mortar_stone','has_superstructure_other','has_superstructure_rc_engineered',\n",
    "    'has_superstructure_rc_non_engineered','has_superstructure_stone_flag','has_superstructure_timber','legal_ownership_status_1' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in binary:\n",
    "    sns.catplot(data = df, x = b , hue = target , kind= 'count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = ['has_secondary_use',\n",
    "        'has_secondary_use_agriculture',\n",
    "        'has_superstructure_adobe_mud',\n",
    "        'has_superstructure_cement_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_stone',\n",
    "        'has_superstructure_timber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[target ]+ numeric + dummies + binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[ ['building_id'] +numeric + dummies + binary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((260601, 36), (86868, 36))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint\n",
    "df.to_csv(\"../data/trainProb.csv\", index = False)\n",
    "test.to_csv(\"../data/testProb.csv\", index = False)\n",
    "\n",
    "#df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "#test = pd.read_csv(\"../data/testProb.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "      <th>age_pt</th>\n",
       "      <th>area_percentage_pt</th>\n",
       "      <th>height_percentage_pt</th>\n",
       "      <th>prob1_geo1</th>\n",
       "      <th>prob1_geo2</th>\n",
       "      <th>prob1_geo3</th>\n",
       "      <th>prob2_geo1</th>\n",
       "      <th>prob2_geo2</th>\n",
       "      <th>prob2_geo3</th>\n",
       "      <th>...</th>\n",
       "      <th>position_t</th>\n",
       "      <th>roof_type_n</th>\n",
       "      <th>roof_type_q</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.627717</td>\n",
       "      <td>-0.374581</td>\n",
       "      <td>-0.116377</td>\n",
       "      <td>0.086461</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.665354</td>\n",
       "      <td>0.251852</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.328256</td>\n",
       "      <td>0.262367</td>\n",
       "      <td>0.896435</td>\n",
       "      <td>0.034277</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.446174</td>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.328256</td>\n",
       "      <td>-0.786085</td>\n",
       "      <td>-0.116377</td>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.082386</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.393378</td>\n",
       "      <td>0.316477</td>\n",
       "      <td>0.360294</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.328256</td>\n",
       "      <td>-0.374581</td>\n",
       "      <td>-0.116377</td>\n",
       "      <td>0.129718</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.739603</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.627717</td>\n",
       "      <td>0.262367</td>\n",
       "      <td>1.706526</td>\n",
       "      <td>0.046959</td>\n",
       "      <td>0.029865</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.568370</td>\n",
       "      <td>0.591522</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260596</th>\n",
       "      <td>2</td>\n",
       "      <td>1.238288</td>\n",
       "      <td>-0.374581</td>\n",
       "      <td>-1.485639</td>\n",
       "      <td>0.083215</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.779516</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260597</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.077843</td>\n",
       "      <td>-0.374581</td>\n",
       "      <td>-0.116377</td>\n",
       "      <td>0.013066</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179388</td>\n",
       "      <td>0.061303</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260598</th>\n",
       "      <td>3</td>\n",
       "      <td>1.238288</td>\n",
       "      <td>-0.374581</td>\n",
       "      <td>0.896435</td>\n",
       "      <td>0.013066</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.179388</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260599</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.328256</td>\n",
       "      <td>1.437087</td>\n",
       "      <td>0.421965</td>\n",
       "      <td>0.354986</td>\n",
       "      <td>0.507429</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.559142</td>\n",
       "      <td>0.452947</td>\n",
       "      <td>0.766949</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260600</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.328256</td>\n",
       "      <td>-0.031040</td>\n",
       "      <td>0.421965</td>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393378</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260601 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        damage_grade    age_pt  area_percentage_pt  height_percentage_pt  \\\n",
       "0                  3  0.627717           -0.374581             -0.116377   \n",
       "1                  2 -0.328256            0.262367              0.896435   \n",
       "2                  3 -0.328256           -0.786085             -0.116377   \n",
       "3                  2 -0.328256           -0.374581             -0.116377   \n",
       "4                  3  0.627717            0.262367              1.706526   \n",
       "...              ...       ...                 ...                   ...   \n",
       "260596             2  1.238288           -0.374581             -1.485639   \n",
       "260597             3 -2.077843           -0.374581             -0.116377   \n",
       "260598             3  1.238288           -0.374581              0.896435   \n",
       "260599             2 -0.328256            1.437087              0.421965   \n",
       "260600             3 -0.328256           -0.031040              0.421965   \n",
       "\n",
       "        prob1_geo1  prob1_geo2  prob1_geo3  prob2_geo1  prob2_geo2  \\\n",
       "0         0.086461    0.003704    0.000000    0.665354    0.251852   \n",
       "1         0.034277    0.010050    0.062500    0.446174    0.492462   \n",
       "2         0.021627    0.082386    0.029412    0.393378    0.316477   \n",
       "3         0.129718    0.019512    0.032258    0.739603    0.853659   \n",
       "4         0.046959    0.029865    0.008197    0.568370    0.591522   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "260596    0.083215    0.172414    0.000000    0.779516    0.724138   \n",
       "260597    0.013066    0.003831    0.000000    0.179388    0.061303   \n",
       "260598    0.013066    0.024024    0.045455    0.179388    0.057057   \n",
       "260599    0.354986    0.507429    0.220339    0.559142    0.452947   \n",
       "260600    0.021627    0.000000    0.000000    0.393378    0.249249   \n",
       "\n",
       "        prob2_geo3  ...  position_t  roof_type_n  roof_type_q  \\\n",
       "0         0.162162  ...           1            1            0   \n",
       "1         0.812500  ...           0            1            0   \n",
       "2         0.360294  ...           1            1            0   \n",
       "3         0.838710  ...           0            1            0   \n",
       "4         0.614754  ...           0            1            0   \n",
       "...            ...  ...         ...          ...          ...   \n",
       "260596    0.928571  ...           0            1            0   \n",
       "260597    0.020408  ...           0            1            0   \n",
       "260598    0.090909  ...           0            0            1   \n",
       "260599    0.766949  ...           0            0            0   \n",
       "260600    0.097561  ...           0            1            0   \n",
       "\n",
       "        has_secondary_use  has_secondary_use_agriculture  \\\n",
       "0                       0                              0   \n",
       "1                       0                              0   \n",
       "2                       0                              0   \n",
       "3                       0                              0   \n",
       "4                       0                              0   \n",
       "...                   ...                            ...   \n",
       "260596                  0                              0   \n",
       "260597                  0                              0   \n",
       "260598                  0                              0   \n",
       "260599                  0                              0   \n",
       "260600                  0                              0   \n",
       "\n",
       "        has_superstructure_adobe_mud  has_superstructure_cement_mortar_brick  \\\n",
       "0                                  1                                       0   \n",
       "1                                  0                                       0   \n",
       "2                                  0                                       0   \n",
       "3                                  0                                       0   \n",
       "4                                  1                                       0   \n",
       "...                              ...                                     ...   \n",
       "260596                             0                                       0   \n",
       "260597                             0                                       0   \n",
       "260598                             0                                       0   \n",
       "260599                             0                                       1   \n",
       "260600                             0                                       0   \n",
       "\n",
       "        has_superstructure_mud_mortar_brick  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "260596                                    0   \n",
       "260597                                    0   \n",
       "260598                                    0   \n",
       "260599                                    0   \n",
       "260600                                    0   \n",
       "\n",
       "        has_superstructure_mud_mortar_stone  has_superstructure_timber  \n",
       "0                                         1                          0  \n",
       "1                                         1                          0  \n",
       "2                                         1                          0  \n",
       "3                                         1                          1  \n",
       "4                                         0                          0  \n",
       "...                                     ...                        ...  \n",
       "260596                                    1                          0  \n",
       "260597                                    1                          0  \n",
       "260598                                    1                          0  \n",
       "260599                                    0                          0  \n",
       "260600                                    1                          0  \n",
       "\n",
       "[260601 rows x 36 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = df.drop([target], axis=1)\n",
    "scaler = RobustScaler()\n",
    "probs = ['prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "clus[probs] = scaler.fit_transform(clus[probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEXCAYAAACDChKsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4YUlEQVR4nO3deVyU9fr/8dewDSAuoIAbgqiJSyruZuExSx0BRT3HtDS31DxkZrmglpplJNmiiXTy2KGjHtyOSi5U59hPWr+J20mE0AAVNwYBFUS2mfv3BzKGg4boLMD1fDx8nJl7mbnmPnS/577vuT+XSlEUBSGEEOI+2Vi6ACGEEDWTBIgQQohqkQARQghRLRIgQgghqkUCRAghRLVIgAghhKgWO0sXIISltW/fnkceeQQbm4rfpyIjI7lw4QJvvfUWe/fuJSwsjHbt2jF16lST1lNUVERUVBQHDx5EURT0ej3BwcFMmzYNlUpl0vcW4n5IgAgBfP7557i5uRlNv3DhglnrUBSFv/71r7Ru3ZqtW7eiVqvJzc1lxowZFBQU8Morr5i1HiHuRU5hCXEfjhw5wpgxYxg2bBgrVqygtLQUgMOHDzNmzBiCg4MZNWoU3377LTqdjr59+3L27FkAPv30UwYOHGh4rcmTJxMfH1/h9RMSEkhLS2PhwoWo1WoAXF1diYiIoFevXgBMmDCBL7/80rDO75937tyZ2bNnM2TIENavX8+MGTMMy6WmpvLEE0+g0+lITU1lypQpjBo1ihEjRrBjxw4TbC1R29XJI5D8/HzGjh3LJ598QsuWLe+6XFpaGkuXLuXatWu4u7vzwQcf0LBhQzNWKsxl4sSJFU5htWzZksjISKPlLl++zKZNm7Czs2Pq1Kls27YNjUbDyy+/TFRUFF27duX06dOMHz+eHTt2MHDgQL777ju8vb357rvvKCkpIT09nSZNmpCcnEy/fv0qvH5iYiJdunTB1ta2wnQfHx98fHz+8HOUlJQwcOBAVq9eTX5+Pn/729/IysrC3d2dnTt3MmrUKBRF4eWXXyYiIoJOnTqRl5fHM888Q9u2benWrVu1tp+om+pcgPzvf//j9ddf58yZM/dcTlEUZs6cyeLFiwkICGDVqlV8+umnzJs3zzyFCrO62ymsO40YMQJnZ2cAhg8fTnx8PC1atKBVq1Z07doVgHbt2tG9e3cOHTrE008/zZYtWwgJCUGr1RIUFMSPP/5Iw4YNeeKJJ3BwcKjw+jY2Njzo6EI9e/YEwMXFhSFDhvDFF18wadIkvvjiC/71r39x5swZzp07x6JFiwzrFBYWkpSUJAEi7kudC5Bt27axdOlS5s+fb5i2e/duPv/8c/R6PZ06dWLp0qWcPn0aZ2dnAgICAHjxxRe5fv26pcoWVuLOIwM7Ozv0er3RcoqiUFpaSv/+/Xn99deJj4+nT58+PPbYY8TExODk5MSwYcOM1uvatSuff/45Op2uwnv98ssvbNy4kffee8/w+uVKSkoqvEZ5wAH85S9/4Y033qBNmza0bdsWLy8vUlJSaNCgAbGxsYblrly5Qv369e9za4i6rs5dA1mxYoXhGxrA6dOn2bZtG1u2bCE2NpbGjRuzYcMGzp07R5MmTViwYAHBwcEsXbq0wn+Yom7at28fxcXFFBUVsXPnTgICAujatSvp6en88ssvQNnfVEJCAr1790atVtOrVy/Wrl1L//796d27N8ePH+fw4cM88cQTRq/v7++Pr68v4eHhFBUVAWU797fffttwutXNzY3ExEQAzp07R0pKyl3rLT+iiIyM5C9/+QsArVu3Rq1WGwLk0qVLBAUFGV5TiKqqc0cgd/r55585e/YsY8aMAcq+zXXs2JGWLVty6NAhNm3axKOPPspHH33Eu+++y7vvvmvhioUp3HkNBODVV1/F0dGxwrSWLVsybtw4CgoKePrppxk5ciQqlYrVq1fz1ltvUVhYiEqlIjw8nNatWwPw9NNP8/XXX9O3b18cHR3x8/OjYcOGhovkd1qzZg0ffvgho0aNwtbWFr1eT0hIiOHnwzNnziQsLIz4+Hh8fX0rfCGqzF/+8hfWrVvHU089BYCDgwPr1q1jxYoV/P3vf6e0tJTZs2fTo0ePam07UXep6upw7k8++ST//Oc/OXDgABkZGbz++usA3LhxA51Ox8mTJwkPD+eLL74A4LfffuPll19m//79lixbCCGsRp07hXWnPn368J///Ifs7GwURWHZsmV8/vnn+Pv7k5OTw6+//grAN998Q6dOnSxcrRBCWI86fwrLz8+Pl156iYkTJ6LX6+nQoQPTp09HrVYTGRnJ66+/zs2bN2natCkRERGWLlcIIaxGnT2FJYQQ4sHU+VNYQgghqqfOnMIqLCwkMTERd3d3o9/yCyGEMKbT6cjKyqJz585Gv0iEOhQgiYmJPPfcc5YuQwghapzNmzdX+nPxOhMg7u7uQNmGaNq0qYWrEUII63f58mWee+45w/7zTnUmQMpPWzVt2vSeAygKIYSo6G6n/eUiuhBCiGqRABFCCFEtEiBCCCGqRQJECCFEtZj9IvrFixeZN28e2dnZtG7dmlWrVlGvXr0Ky2i1WhYuXMiVK1ewsbFh/vz59OvXj5KSEvr06YOXl5dh2Z07d8p9HUIIYQFmPwJ58803efbZZ/nyyy/p3Lkz69atM1omIiKCgQMHEhsby/vvv8/cuXPR6XSkpKTg7+9PbGys4Z+EhxBC3JupRqwy6xFISUkJCQkJhl7To0aNYvz48UZtYgcPHkyfPn0A8Pb2pqioiIKCAk6cOEFOTo6hd8fcuXPp3bu3OT+CEEKYlKIoFBXruFlcys2iUgqLdNwsKq3wr/CO5zeLSiks1nGz8Nbz4orL9fDz5PUpfR56rWYNkNzcXFxcXLCzK3tbd3d3MjMzjZYbPHiw4fGGDRvo0KED9evXR6VSMWjQIEJDQ0lOTmbatGns2bOnSr2shRDCFPR6hcJi4x36zcJSbhbrDI8rW6YsHEq4eSskCovLdvr6Kh4w2NvZ4KS2w1Fth7PaDkcHW5wd7WjcyBFHh1vT1HZ0btPYJJ/dZAESFxdHeHh4hWk+Pj5Gy6lUqru+RnR0NFu3bmXTpk0AjB071jCvY8eOdOnShaNHjxo6rQkhxB+5c4f/+2/4Bb/b+VfY4RfenldYXHr7m/6tb/5V5ehga9jhO93616i+I82alO38nRxvTXeww8nRDkeHsudlQWBbMSzUdtjZWvZ3UCYLEI1Gg0ajqTCt/CK4TqfD1taWrKwsPDw8Kl0/IiKC+Pj4CkOP7N69m+7du9OqVSug7FDP3t7eVB9BCGGldDo91wuKuZ5fzPUbxVy7UcT1G7ce5xeRd6OEgqKSCgFwOxDuf4fvpLYz7Nxd6zvSosnt57//V75zv/389vqODnbY2Nz9C3NNZNZTWPb29vTs2ZP9+/cTHBzM7t27CQgIMFouOjqan3/+mZiYGBo0aGCYnpKSwvHjx1m2bBlpaWkkJydLH2chajhFUbhZVFohAMr+t5jrvwuG38/Lv1ly19er52hHg3pqox2+4x07+9vf9m0rD4NauMN/2MzeUOrChQuEhYWRnZ1Ns2bN+OCDD2jYsCExMTFotVpefvllevfujYuLS4Xw+PTTT6lXrx6LFi0iLS0NlUrF4sWL6du3b5Xe9/z58wwaNIgDBw7IWFhCmFCpTk/ejYpHBtduHSlcz//dkcLv5pXq9JW+lp2tigb11DSo50BDFwca1FPTsJ4DDeo50MCl4vQGt6Zb+rRObfJH+80605FQAkSIB3OzqJTc64XkXC8k93oROXmF5FwrJCev8Nb0InKvF9776MDJvmynX8/hjmC49dzl9ryGLg44qe3ueZ1UmNYf7TfrzGi8QghjiqJQUFhKjiEYyoLA8Ph34XCzqNRofTtbG9waqHFt4EhLDxcebdOYRi5qo6ODhvUcqC9HB7WOBIgQtZCiKOQVlNwRDIXk5hWVHTVcLyQ3rywYikuMLyo72NvSuIEjrg3U+DRvSHc/R1zrq2nc0BHX+o64NXDEtYEj9Z3t5QihDpMAEaKGKQ8HbU4BmbkFaHPK/l25dtNwain3elGl1xWc1Ha4NSgLgEdauZYFQX1H3Bo6lh1J3AoHZ0c5dST+mASIEFbmbgFheJxbYPRTVGdHOxo3dKJxA0c6uzc2HCGUh4VrAzVu9R1xVMt/8uLhkb8mIcxMURSu3yhGm1uANucmmbdCofx/tTkFRjenOTva4enmTNPG9ejazh0PN2c8XJ3xdHPGw80ZFye5H0qYnwSIEA9ZdQKinpM9Hq5ONGtcj24SEKKGkAARoppy8wr5LeMqGZn5VQoIT1dnmjepR7dH3PF0LQsGTzdn3F0lIETNJAEiRBXk3yzht4xcTmdcNfy7cvWmYb4EhKiLJECEuENhUSmpF65xOuMqv2Vc5XRGLhev3DDMb9akHh193GjXqhHtvFzxbtZAAkLUSRIgok4rKdVz5lJZWJw+VxYWGZl5huG0mzR0pF0rVwb1akU7r0a082qEi7ODZYsWwkpIgIg6Q6dXOJ+Zx+mMXE7dOg115uJ1w/0SDeo50M6rEX0fbcYjXq6082qEawNHC1cthPWSABG1kqIoXLpy43fXLHJJvXCNolsXt53UdrTzasSIAF/aepWdivJwdZKb54S4DxIgosZTFIUrVws5nZHLb+dvnYo6f5Ubtwb1c7CzwbdFQwb38aZty7LTUC3cXWSobiEekASIqHFKSvX8eiaHxNQrnD5fdoRxNa8IAFsbFd7NGvB41+a0u3UaqlXT+jKInxAmIAEirF756aijKVqOpWRxIjWLm0U6VCpo6eFC9/YetPNqRFuvRrRu3hC1va2lSxaiTpAAEVbpxs0Sfvkti6MpWRxL0ZKZUwBA08bO/KmHF/6PeNClbRPqyc9nhbAYswfIxYsXmTdvHtnZ2bRu3ZpVq1ZRr149o2UCAwMNvc+bNGnChg0bKC4uZvHixSQmJuLo6MiqVato06aNuT+CMAGdXiH1/FWOpmg5+quWlHO56PUKTmpburR1Z+Sf2uLf3p3mTVwsXaoQ4hazB8ibb77Js88+S2BgIJGRkaxbt4558+ZVWObEiRMEBwezfPnyCtM3btyIk5MTcXFxJCQkEBYWxvbt281ZvniIrly9ybEULUdTtPzvdBZ5BWUXvdu2bMjogW3xb++Bn7cb9nZy/UIIa2TWACkpKSEhIYHIyEgARo0axfjx4ysNkFOnTjFq1ChcXFxYvHgx7du35+DBg8yePRuAXr16kZuby8WLF2nevLk5P4aopqISHSdTs8uOMlK0ZGTmAeDWQE2vjk3p3t6Dbo+409BFbeFKhRBVYdYAyc3NxcXFBTu7srd1d3cnMzPTaDm1Wk1ISAhjx44lPj6e0NBQ9u/fj1arxd3d3bCcu7s7ly9flgCxUoqicO5yniEwTqZlU1Kqx97Ohk6tG/NUr1Z09/PAu2l9uf9CiBrIZAESFxdHeHh4hWk+Pj5Gy1W245g1a5bh8YABA3j//fdJS0ur9H1sbOT0hjW5ll/E8VNZHDtV9oupnOuFAHh51kfzmA/d23vQybcxjg7y+w0hajqT/Ves0WjQaDQVppWUlNCnTx90Oh22trZkZWXh4eFhtO7GjRsJCgrC1dUVKPsma2dnh4eHB1lZWXh7ewPcdX1hPqW6snsyjqZoOXYqi9TzV1EUcHGyp9sj7vi398D/EQ/cXZ0sXaoQ4iEz69dAe3t7evbsyf79+wkODmb37t0EBAQYLZeQkEBhYSHTpk3j0KFD6PV6fH19GTBgALGxsfTs2ZPDhw+jVqvl9JUFXM6+wZFftRxL0fLLb1e4WVSKjY2K9q1ceXaIH/6PuNPWyxVbudNbiFrN7OcRli5dSlhYGFFRUTRr1owPPvgAgJiYGLRaLbNnz2bx4sWEhYURGxuLWq3m/fffx8bGhgkTJrBkyRICAwNxcHAgIiLC3OXXaYVFpfz9i0S++r+zAHi4OTOge0u6t3fn0bbuMqS5EHWMSlEUxdJFmMP58+cZNGgQBw4coGXLlpYup8Y5dS6X9zcf4VL2DUYEtEHTz4dmTerJxW8harE/2m/KlUxxTzq9wr+/Oc2/vvoV1/pqVrzYn0fbNrF0WUIIKyABIu5Km1PABzFHOZmWzeNdmxP6567STEkIYSABIioVf/Q8Uf/+H3oF5ozzZ2APLzldJYSoQAJEVHDjZgmf7PyFg0fP08HHjVef7U7TxvX+eEUhRJ0jASIMTqZl88G/jnDlWiHPDvFjzKB22EofDSHEXUiACEp1emK+TmHHgVN4uDmz8qXH8fN2s3RZQggrJwFSx13MymfV5iOczrjKU71aMS2kM86Ocj+HEOKPSYDUUYqi8PXP5/h77AnsbG0Ie74X/bvKXf1CiKqTAKmDrt8oZu324/x04hJd2jZhzrjuNGkkY1UJIe6PBEgdcyxFy0dbjnL9RjGTgzoRMqANNjJmlRCiGiRA6ojiEh3/3J9M7LepeHm6sPSFfvi2aGjpsoQQNZgESB1w9vJ1Vm06wplL1wns35pJQR2lH4cQ4oHJXqQWUxSFPd+nEb03iXqO9iyZ2odeHZtauiwhRC0hAVJL5V4v5KOtxzj6q5aeHTyZ/Yw/jepLr3EhxMMjAVIL/Zx4iTXbjlNYVMrM0V3Q9PORcayEEA+d2QPk4sWLzJs3j+zsbFq3bs2qVauoV6/iWEsvvvgily5dAkCv13Pq1Cl27NiBn58fffr0wcvLy7Dszp07sbW1NetnsFaFRaVs2HOSL386g2+Lhsx9rgdenvUtXZYQopYye4C8+eabPPvsswQGBhIZGcm6deuYN29ehWU++eQTw+PVq1fTrVs3Hn30URITE/H392fDhg3mLtvq/ZZxlVWbj3DxSj6jB7bluaEdsLeTcayEEKZj1j1MSUkJCQkJDBkyBIBRo0bx5Zdf3nX51NRUdu/ezYIFCwA4ceIEOTk5jBkzhjFjxnDo0CGz1G3NdHqF7QdOMXfNtxQWl/L2i48xKaiThIcQwuTMegSSm5uLi4sLdnZlb+vu7k5mZuZdl4+KimLq1Km4uLgAoFKpGDRoEKGhoSQnJzNt2jT27NmDm1vdHPhPm1vAhzFHSUzNpv+thk/1peGTEMJMTBYgcXFxhIeHV5jm4+NjtNzdLu5eu3aNH374gRUrVhimjR071vC4Y8eOdOnShaNHj/LUU089nKJrkO+OXSByx3H0isIrY/15sqc0fBJCmJfJAkSj0aDRaCpMKykpoU+fPuh0OmxtbcnKysLDw6PS9ePj4wkICECtvv3T0927d9O9e3datWoFlN3nYG9ft0aOLSgsa/j0/46cp723K68924NmTaThkxDC/Mx6otze3p6ePXuyf/9+oCwQAgICKl32+PHj9OzZs8K0lJQUPvvsMwDS0tJITk6mR48epi3aiiSlZzPr/YPEHz3Ps4PbszL0cQkPIYTFmP1K69KlS9m2bRvDhg3j8OHDvPLKKwDExMSwevVqw3IZGRl4enpWWDc0NJScnByCgoKYPXs2K1euNFwfqe2ycm+yOOoHbFSw8qUnGDfET7oFCiEsyuw/423RogUbN240mj5u3LgKz9evX2+0jIuLC2vWrDFZbdbsRGoWpTqFRZN607q5DIIohLA8+QpbQySl51DP0Q7vpg0sXYoQQgASIDVGUno2HVo3lt4dQgirIQFSA1zLLyIjM5+Orevm/S5CCOskAVID/HomB4COrRtbuBIhhLhNAqQGOJmeg52tDe28Glm6FCGEMJAAqQGS0rNp59UIB3sZdVgIYT0kQKxcYXEpqeevyvUPIYTVkQCxcqczrlKqU+jkK9c/hBDWRQLEyiWlZQPQwUeOQIQQ1kUCxMolpefg3bQ+LjJMuxDCykiAWDGdXiH5TI78fFcIYZUkQKzY2UvXuVlUSke5/iGEsEISIFYsKb3s+of8AksIYY0kQKzYybRsmjRywsPV2dKlCCGEEQkQK6UoCknpOXL0IYSwWhYLkNWrV/Pxxx9XOq+4uJh58+ah0WgYOXIkqampQNlOdeXKlQwdOpRhw4Zx5MgRc5ZsVpk5BeRcL5QL6EIIq2X2AMnLy2PRokWG1rSV2bhxI05OTsTFxbFo0SLCwsIA+Oqrr0hNTWX//v1ERkYSFhZGaWmpuUo3q6T0sgEU5QZCIYS1MnuAHDhwAB8fHyZPnnzXZQ4ePMjw4cMB6NWrF7m5uVy8eJH4+HiGDRuGjY0NrVu3pnnz5hw7dsxcpZtVUno29RztaOVZ39KlCCFEpcweICEhIUyfPh1b27sPDKjVanF3dzc8d3d35/Lly2i1Wjw8PIym10bSQEoIYe1M1hM9Li6O8PDwCtN8fX2Jjo6u1uvZ2NigKEql02ub8gZSA3t4WboUIYS4K5MFiEajQaPRVGtdDw8PsrKy8Pb2BiArKwsPDw88PT3JysoyLFc+vbaRBlJCiJrAKr++DxgwgNjYWAAOHz6MWq2mefPmBAQEsGfPHnQ6HWfPnuXMmTM8+uijFq724UuSBlJCiBrAZEcg9ysmJgatVsvs2bOZMGECS5YsITAwEAcHByIiIgAYOnQov/zyi+EC+4oVK3B0dLRk2SZxUhpICSFqAJVS2YWFWuj8+fMMGjSIAwcO0LJlS0uXc1eFxaWMe30/IwLaMCmok6XLEULUYX+037TKU1h1WXkDKRlAUQhh7SRArEz5AIrSQEoIYe0kQKxMeQOp+tJASghh5SRArIhOr/CrNJASQtQQEiBW5Oyl6xQUlsoIvEKIGkECxIrcbiAlRyBCCOsnAWJFktJzyhpIuUkDKSGE9atSgNy4cYM333yTiRMncvXqVZYsWcKNGzdMXVudoigKJ9Oy5fSVEKLGqFKAvP322zRo0IDs7GzUajX5+fksWbLE1LXVKdJASghR01QpQJKTk5kzZw52dnY4OTmxatUqkpOTTV1bnVLeQEqOQIQQNUWVAuTOIdN1Ol2tHEbdkgwNpJo2sHQpQghRJVUaTLFXr1689957FBYW8t1337F582b69Olj6trqlKT0HDq0boytNJASQtQQVTqMmDt3Ls7OztSvX58PP/yQ9u3bM3/+fFPXVmdcv1FMRmaenL4SQtQoVToCWbNmDa+99hqhoaGmrqdOSpb7P4QQNVCVjkAOHjxo4jLqNmkgJYSoiap0BNKyZUumTJlC9+7dqVevnmH65MmTTVZYXZIkDaSEEDVQlQKkUaNGAFy4cOGhvfHq1auxsbFh1qxZRvO0Wi0LFy7kypUr2NjYMH/+fPr160dJSQl9+vTBy8vLsOzOnTuxta25O96iEh2/nb/KiIA2li5FCCHuS5UCJDw8HCgLkNLSUry9vav9hnl5eYSHh7Nv3z5eeOGFSpeJiIhg4MCBjB8/nrS0NCZMmMC3335LSkoK/v7+bNiwodrvb21OncuVBlJCiBqpSgFy9uxZ/vrXv6LVatHr9bi6uvK3v/2NNm3u/1vzgQMH8PHxuefpr8GDBxt+Juzt7U1RUREFBQWcOHGCnJwcxowZA5T9Oqx37973XYM1kQZSQoiaqkoX0ZcvX84LL7xAQkICR44cYebMmbz55pvVesOQkBCmT59+z9NOgwcPpmHDhgBs2LCBDh06UL9+fVQqFYMGDWLr1q0sW7aMOXPmkJOTU606rEVSeg6tpIGUEKIGqtIRSHZ2NiNHjjQ8Hz16NNHR0fdcJy4uznDqq5yvr+8frvd70dHRbN26lU2bNgEwduxYw7yOHTvSpUsXjh49ylNPPVXl17Qm5Q2kAvyNm9ULIYS1q1KA6HQ6rl69ariYXpVv/RqNBo1GU+3CIiIiiI+PZ/PmzTRt2hSA3bt30717d1q1agWUjWBrb29f7fewtHOXyxpIdZIbCIUQNVCVAmT8+PE888wzhkCIi4tj4sSJJisqOjqan3/+mZiYGBo0uD02VEpKCsePH2fZsmWkpaWRnJxMjx49TFaHqZ1MkxsIhRA1V5UC5JlnnsHb25vvvvsOvV7PsmXL6Nev30MtJCYmBq1Wy8svv0xkZCQuLi5MmDDBMP/TTz8lNDSURYsWERQUhEqlYuXKlbi4uDzUOswpKT2HJg0dcXd1snQpQghx36oUIJmZmXz55ZeGb/6rVq2ibdu2uLu7V/uN77z/Y9y4cYbHCQkJd11vzZo11X5Pa1LeQKqzb2NUKhlAUQhR81TpV1gLFizA19cXgBYtWtC7d28WLVpk0sJqO23uzbIGUnL/hxCihqpSgOTm5vL8888DoFarmTRpEllZWSYtrLZLMgygKBfQhRA1U5UCRKfTkZmZaXh+5coVFEUxWVF1wck0aSAlhKjZqnQNZNKkSYSEhPDEE08A8NNPP0k/kAeUlJ6Dn4+bNJASQtRYfxggiqIQEhJC586d+e9//4uNjQ1Tp06lffv25qivVipvIPWn7nIDoRCi5rrnKazffvuNQYMG8d133+Hj48PevXvZu3cvM2fO5IcffjBXjbXOr2fKbsTsJBfQhRA12D0DJCIigldeeYWBAweyb98+VCoVe/fuZfPmzXz88cfmqrHWSUrPlgZSQoga754BcunSJYYPHw7Azz//zKBBg7CxsaFZs2bk5+ebpcDa6GSaNJASQtR89wwQG5vbs48dO0avXr0Mz4uKikxXVS1W3kBKfr4rhKjp7nkRvWHDhvz666/k5+eTlZVlCJCjR4/i6elplgJrm9PlDaRk/CshRA13zwB59dVXmTRpEvn5+cydOxdnZ2c2bNjAJ598QmRkpLlqrFWS0ssuoHeQIxAhRA13zwDp1q0b3377LYWFhYZRcf39/dm+fTs+Pj7mqK/WOZmeLQ2khBC1wh/eB+Lg4ICDw+2dXffu3U1aUG0mDaSEELVJlYYyEQ9HeQMpuYAuhKgNJEDMKEkaSAkhapEqjYVlCqtXr8bGxsaoLwjAxYsXCQwMNLSubdKkCRs2bKC4uJjFixeTmJiIo6Mjq1atok2bNuYuvdrKG0h5SAMpIUQtYPYAycvLIzw8nH379vHCCy9UusyJEycIDg5m+fLlFaZv3LgRJycn4uLiSEhIICwsjO3bt5uj7AemKAon07Pp1FoaSAkhagezn8I6cOAAPj4+TJ48+a7LnDhxglOnTjFq1Cief/55UlJSADh48KDhzvhevXqRm5vLxYsXzVL3g9Lm3iT7WqFc/xBC1BpmD5CQkBCmT5+Ore3dh/FQq9WEhISwc+dOpk6dSmhoKMXFxWi12gptdN3d3bl8+bI5yn5ghgZSMoCiEKKWMNkprLi4OMLDwytM8/X1JTo6+g/X/f11kQEDBvD++++TlpZW6bK/H27FmiWl5+AsDaSEELWIyQJEo9Gg0Wiqte7GjRsJCgrC1dUVKLt+YGdnh4eHB1lZWXh7ewOQlZWFh4fHQ6vZlJLSs+kgDaSEELWIVX59T0hIYMeOHQAcOnQIvV6Pr68vAwYMIDY2FoDDhw+jVqtp3ry5JUutkus3ijl3OU9+viuEqFUs9jPeO8XExKDVapk9ezaLFy8mLCyM2NhY1Go177//PjY2NkyYMIElS5YQGBiIg4MDERERli67SsobSMkFdCFEbWKxALnz/o9x48YZHnt6evKPf/zDaB21Ws3KlStNXtvDVtZASkW7Vq6WLkUIIR4aqzyFVdskpefQzssVtTSQEkLUIhIgJlZUouN0Rq6cvhJC1DoSICYmDaSEELWVBIiJlTeQ8vORIxAhRO0iAWJiSenZeHnWp0E9aSAlhKhdJEBMqLyBVCcZvkQIUQtJgJjQucvXuSENpIQQtZQEiAlJAykhRG0mAWJCSek5NJYGUkKIWkoCxETKG0h1lAZSQohaSgLERLJuNZDqJNc/hBC1lASIiZyUBlJCiFpOAsREpIGUEKK2kwAxkaT0bPykgZQQohaTADGBvILyBlJy/UMIUXtZrB/I6tWrsbGxMeoLAvDiiy9y6dIlAPR6PadOnWLHjh34+fnRp08fvLy8DMvu3LkTW1vrGiY9+VYDqU5y/4cQohYze4Dk5eURHh7Ovn37eOGFFypd5pNPPjE8Xr16Nd26dePRRx8lMTERf39/NmzYYK5yqyUpTRpICSFqP7MHyIEDB/Dx8WHy5Ml/uGxqaiq7d+9mz549AJw4cYKcnBzGjBkDwNy5c+ndu7dJ662OpPQc2rZsJA2khBC1mtmvgYSEhDB9+vQqnXaKiopi6tSpuLi4AKBSqRg0aBBbt25l2bJlzJkzh5ycHFOXfF9uN5CS01dCiNrNZEcgcXFxhIeHV5jm6+tLdHR0lda/du0aP/zwAytWrDBMGzt2rOFxx44d6dKlC0ePHuWpp556KDU/DL9lXKVUp8gIvEKIWs9kAaLRaNBoNNVePz4+noCAANRqtWHa7t276d69O61atQLKhguxt7d/4FofppO3BlCUBlJCiNrOan/Ge/z4cXr27FlhWkpKCp999hkAaWlpJCcn06NHD0uUd1fSQEoIUVdYTYDExMSwevVqw/OMjAw8PT0rLBMaGkpOTg5BQUHMnj2blStXGq6PWIPyBlJy/4cQoi6w2H0gd97/MW7cuArP169fb7SOi4sLa9asMWldD+J2Aym5/iGEqP2s5gikNkhKv3UDoVxAF0LUARIgD1FSWrY0kBJC1BkSIA+JNJASQtQ1EiAPSXkDKbmALoSoKyRAHpKk8gZScgFdCFFHSIA8JOUNpLybSQMpIUTdIAHykJyUBlJCiDpGAuQhkAZSQoi6SALkIShvICXXP4QQdYkEyENQ3kDqEWkgJYSoQyRAHgJpICWEqIskQB5QcYmO0xlX5fSVEKLOkQB5QKczrlKq08sFdCFEnSMB8oDKbyCUBlJCiLpGAuQBJaXn4OXpQkMX9R8vLIQQtYgEyAPQ6RWSbw2gKIQQdY3ZA+TIkSOMHj2aESNGMHHiRC5cuGC0THFxMfPmzUOj0TBy5EhSU1OBshFvV65cydChQxk2bBhHjhwxd/kVSAMpIURdZvYAmTdvHitWrCA2Npbg4GDefvtto2U2btyIk5MTcXFxLFq0iLCwMAC++uorUlNT2b9/P5GRkYSFhVFaWmruj2BQ3kBKLqALIeoiswZIcXExs2fPxs/PD4D27dtz6dIlo+UOHjzI8OHDAejVqxe5ublcvHiR+Ph4hg0bho2NDa1bt6Z58+YcO3bMnB+hgqT0bNwaOOLp5myxGoQQwlLMGiAODg6MGDECAL1ez9q1a3nqqaeMltNqtbi7uxueu7u7c/nyZbRaLR4eHkbTLSUpPYdOvtJASghRN9mZ6oXj4uIIDw+vMM3X15fo6GiKi4sNp59mzJhRpdezsbFBUZRKp1uCNqeAK1dvyukrIUSdZbIA0Wg0aDQao+k3btxg5syZNGrUiKioKOzt7Y2W8fDwICsrC29vbwCysrLw8PDA09OTrKwsw3Ll0y1BGkgJIeo6i1xE9/b2ZvXq1Tg4OFS6zIABA4iNjQXg8OHDqNVqmjdvTkBAAHv27EGn03H27FnOnDnDo48+as7yDZLSc3BSSwMpIUTdZbIjkMokJSVx4MAB2rZtS0hICFB2tLF+/XpiYmLQarXMnj2bCRMmsGTJEgIDA3FwcCAiIgKAoUOH8ssvvxgusK9YsQJHR0dzfoTbnyU9mw7SQEoIUYeZNUA6duxISkpKpfPGjRtneKxWq1m5cqXRMiqVigULFrBgwQKT1VgV+QXFnL2cxxP+LSxahxBCWJLciV4NSdJASgghJECqo7yBVDuvRpYuRQghLEYCpBqS0nNo07IRjg5mPQMohBBWRQLkPkkDKSGEKCMBcp/KG0h1khsIhRB1nATIfZIGUkIIUUYC5D5JAykhhCgjAXIf9NJASgghDCRA7sO5zLxbDaTk9JUQQkiA3IeTaTKAohBClJMAuQ/SQEoIIW6TALkPSek5dGztJg2khBACCZAq0+aWN5CS01dCCAESIFWWlF42gGInXwkQIYQACZAqS0rLlgZSQgjxO2YfDfDIkSO88847lJaW0qhRI9555x1atKjYV0Or1bJw4UKuXLmCjY0N8+fPp1+/fpSUlNCnTx+8vLwMy+7cuRNbW1uT1y0NpIQQoiKzB8i8efNYt24dfn5+7Nixg7fffpuoqKgKy0RERDBw4EDGjx9PWloaEyZM4NtvvyUlJQV/f382bNhg1poNDaS6SQMpIYQoZ9ZTWMXFxcyePRs/Pz8A2rdvz6VLl4yWGzx4MMHBwQB4e3tTVFREQUEBJ06cICcnhzFjxjBmzBgOHTpklrqTpYGUEEIYMesRiIODAyNGjABAr9ezdu1annrqKaPlBg8ebHi8YcMGOnToQP369VGpVAwaNIjQ0FCSk5OZNm0ae/bswc3NtHeGJ6XnlDWQatXIpO8jhBA1ickCJC4ujvDw8ArTfH19iY6Opri4mLCwMEpLS5kxY8ZdXyM6OpqtW7eyadMmAMaOHWuY17FjR7p06cLRo0crDaGH6WRatjSQEkKIO5hsj6jRaNBoNEbTb9y4wcyZM2nUqBFRUVHY29tXun5ERATx8fFs3ryZpk2bArB79266d+9Oq1atAFAU5a7rP0zXbxQzsEdLk7+PEELUJGb/Ge+8efPw9vZm9erVODg4VLpMdHQ0P//8MzExMYbwAEhJSeGzzz4DIC0tjeTkZHr06GHymj96dQB/HvSIyd9HCCFqErOek0lKSuLAgQO0bduWkJAQADw8PFi/fj0xMTFotVpefvllIiMjcXFxYcKECYZ1P/30U0JDQ1m0aBFBQUGoVCpWrlyJi4uLyeuWU1dCCGHMrHvGjh07kpKSUum8cePGGR4nJCTc9TXWrFnz0OsSQghx/+ROdCGEENUiASKEEKJaJECEEEJUiwSIEEKIapEAEUIIUS115vepOp0OgMuXL1u4EiGEqBnK95fl+8871ZkAycrKAuC5556zcCVCCFGzZGVl4e3tbTRdpSiKYoF6zK6wsJDExETc3d3N0j9ECCFqOp1OR1ZWFp07d8bR0dFofp0JECGEEA+XXEQXQghRLRIgQgghqkUCRAghRLVIgAghhKgWCRAhhBDVIgEihBCiWiRAhBBCVIsEiAWsXbuWwMBAAgMDiYiIqHT+wIEDGTFiBCNGjGDz5s0WqBKef/55AgMDDXX873//qzD/xx9/JDg4mMGDB/Phhx9apEaA7du3G2ocMWIEPXr0YPny5RWWseQ2zc/PJygoiPPnzwNV224XL17kueeeY+jQocycOZMbN25YpNatW7cSFBREcHAwCxcupLi42Gid3bt38/jjjxu2rTn+Fu6sc+HChQwePNhQw3/+8x+jdZKTkxk9ejRDhgxh8eLFlJaWmrXO+Pj4Cn+nffv2ZcaMGUbrWGJ7VpsizOqHH35QnnnmGaWoqEgpLi5Wnn/+eeXrr7+usMyMGTOUo0ePWqjCMnq9Xunfv79SUlJS6fybN28qAwYMUM6dO6eUlJQoU6ZMUQ4ePGjmKo2dOnVKefrpp5Xs7OwK0y21TY8fP64EBQUpnTp1UjIyMqq83aZPn67s3btXURRFWbt2rRIREWH2WtPS0pSnn35aycvLU/R6vTJ//nzlH//4h9F6y5cvV/bs2WPy+u5Wp6IoSlBQkJKZmXnP9QIDA5Vjx44piqIoCxcuVDZv3mz2OstptVpl0KBBSnp6utF65t6eD0KOQMzM3d2dsLAwHBwcsLe3p02bNly8eLHCMomJiaxfv57g4GCWL19OUVGR2etMS0tDpVIxbdo0hg8fzqZNmyrM/+WXX/D29sbLyws7OzuCg4P58ssvzV7nnZYtW8acOXNwc3OrMN1S23Tbtm0sXboUDw8PoGrbraSkhISEBIYMGQLAqFGjzLJt76zVwcGBZcuW4eLigkql4pFHHjH6WwU4ceIEu3fvZvjw4cydO5dr166Ztc6CggIuXrzIG2+8QXBwMGvWrEGv11dY58KFCxQWFtKtWzfAPNv0zjp/LyIigrFjx+Lj42M0z9zb80FIgJhZu3btDH/EZ86cYf/+/QwYMMAw/8aNG3To0IEFCxawa9curl+/zrp168xe5/Xr1+nXrx+RkZFER0ezZcsWfvjhB8N8rVaLu7u74bmHhweZmZlmr/P3fvzxRwoLC9FoNBWmW3Kbrlixgp49exqeV2W75ebm4uLigp1d2Vin7u7uZtm2d9baokULHnvsMQBycnLYvHkzgwYNMlrP3d2dWbNmERsbS7NmzYxOH5q6zuzsbPr27cs777zDtm3bOHz4MDt27Kiwzp3b3Rzb9M46y505c4ZDhw7x/PPPV7qeubfng5AAsZDTp08zZcoUFixYUOFbSL169Vi/fj3e3t7Y2dkxZcoU4uPjzV6fv78/ERERODs74+bmxp///OcKdSiVDKGmUqnMWaKRLVu2MHnyZKPp1rJNoWrbzdq2bWZmJhMnTmT06NH06dPHaH5kZCRdu3ZFpVLxwgsv8O2335q1Pi8vLyIjI2ncuDFOTk5MmDDB6P9fa9qmW7du5dlnn8XBwaHS+ZbenvdDAsQCjhw5wqRJk3jttdcYOXJkhXkXL16s8O1JURTDN1FzOnz4MD/99NNd6/D09OTKlSuG51qtttJDdXMpLi4mISGBJ5980mietWxTqNp2c3NzIz8/39CDISsry2LbNjU1lXHjxjFy5EhCQ0ON5ufl5REdHW14boltm5KSwldffXXPGu7c7pbcpgcOHGDYsGGVzrOG7Xk/JEDM7NKlS4SGhrJq1SoCAwON5js6OvLee++RkZGBoihs3ryZp59+2ux15uXlERERQVFREfn5+ezatatCHV27diU9PZ2zZ8+i0+nYu3cvAQEBZq+zXEpKCj4+Pjg7OxvNs5ZtClXbbvb29vTs2ZP9+/cDZb/KscS2zc/PZ+rUqcyePZspU6ZUuoyzszN///vfDb/Q27Rpk9m3raIovPPOO1y7do2SkhK2bt1qVEOLFi1Qq9UcOXIEsNw2zcnJobCwEC8vr0rnW8P2vB8SIGa2YcMGioqKePfddw0/04uJiWHatGmcOHECNzc3li9fzsyZMxk6dCiKolR6WsbUBg4cyIABAwgJCWH06NGMHj0af39/RowYQWZmJmq1mnfffZdZs2YxbNgwfH19GTp0qNnrLJeRkUHTpk0rTLO2bQrcc7stXryYAwcOALB06VK2bdvGsGHDOHz4MK+88orZa92xYwdXrlzhs88+M/ytrl69ukKttra2fPTRRyxbtgyNRsPJkyeZN2+eWev08/Nj+vTpjBs3jsDAQDp06EBQUBBw+28AYNWqVYSHh6PRaLh58+Zdr0GY0vnz543+TsG6tuf9kH4gQgghqkWOQIQQQlSLBIgQQohqkQARQghRLRIgQgghqkUCRAghRLVIgIga6fz587Rv357t27dXmL5hwwbCwsIe2vs8+eSThp+Bmlp+fj5jx44lMDCwwo1x5VJTU5k1axbBwcEMHz6c8ePHc/jwYaBse/j7+1f7vQ8ePGj4ia4QVWW9tzgK8QdsbGxYuXIlPXv2pHXr1pYu54ElJyeTnZ1d6VDkaWlpTJw4kfDwcJ544gkAfvrpJ1588UViYmJwcnJ6oPc+ceKEVQ/aJ6yTBIiosRwdHZk8eTKvvfYaW7ZsMRpbKCwsjHbt2jF16lSj508++SRBQUEcPHiQq1evMmvWLI4ePcrJkyexs7MjKioKT09PAP71r3/x66+/UlxczOTJk/nzn/8MwDfffENUVBQlJSU4OjqyYMEC/P39+fjjjzl+/DharZb27duzatWqCnX997//Ze3ateh0OlxcXFi4cCEuLi4sWrSIzMxMRowYwdatW3F0dDSss379ekaPHm0ID4B+/frx/vvvV1gO4OOPPyY3N5clS5YYPf/666+JiopCpVJha2vL/PnzcXBwYMuWLeh0OurXr8+cOXPYvn07MTEx6PV6GjVqxBtvvEGbNm0ICwvj6tWrZGRk8Kc//YmBAwfy7rvvGka/nTFjhmEUYVH7SYCIGm3mzJn8+OOPfPjhhyxYsOC+1i0qKuKLL75g//79vPbaa+zatQs/Pz9CQ0PZtWsXL774IlB29/iuXbvIzMwkJCSErl27Ym9vz4cffsg///lPXF1dOX36NJMnT+brr78GyoYP37t3r9E4RqmpqSxdupQtW7bg5eXFTz/9xF//+le+/PJL3n77bd566y1iY2ONak1MTGTu3LlG08tHci5vrPRHIiIiWLVqFd26deP777/n559/5qWXXmLs2LHk5uYyZ84cDh06xO7du9m8eTNOTk58//33zJo1yzC0SmFhIfv27QNg4sSJTJ48mcDAQH799Ve2bt0qAVKHSICIGs3Gxob33nuPkSNH8vjjj9/XuoMHDwbKRnNt0qQJfn5+ALRq1arC6ZyxY8cCZQPyPf744/z000/Y2tqi1WqZNGmSYTmVSsW5c+cA6NatW6WD4P3f//0fffv2NYyF1K9fP9zc3EhMTLzn6LAqlcqox0V1BAYG8tJLLzFgwAD69+/PtGnTjJY5ePAgZ8+eNXxugGvXrnH16lUAevToYZiu0WhYvnw533zzDY899hivvvrqA9coag65iC5qvObNm7Ns2TIWLFhAbm6uYbpKpaowjHdJSUmF9X5/ysve3v6ur29jc/s/k/LRUfV6Pf369SM2Ntbwb9u2bbRr1w6g0kEdy9evbNoftVft1q0bx48fN5q+du1avvjiiwrT7vW558yZQ0xMDJ07d2bnzp0888wzRsGk1+sZMWKE4XPt2rWLf//73zRs2NDos40dO5YvvviC/v378/333zN8+HDy8vLu+VlE7SEBImoFjUZDQEAAn3/+uWGaq6sriYmJQNkoqOW/WLpfu3btAsqGhf/xxx/p168fffv25YcffiA1NRWA+Ph4hg8f/oedDsvXy8jIAMouhF+6dImuXbvec72pU6eyfft2vv/+e8O0b7/9lo0bNxqOnMq5urpy8uRJFEWhoKDAsE5paSlPPvkkBQUFjBs3jqVLl5KamkppaSm2traGEOvfvz/79u1Dq9UCEBMTw8SJEyuta+zYsSQnJzNq1Cjeeustrl+/Lhfj6xA5hSVqjddff90wXDfAhAkTmDt3LkOGDKFly5b07t27Wq9bVFTEyJEjKSkp4fXXXzf84mv58uW8+uqrhqOSqKioux55lGvbti1Lly7lpZdeQqfT4ejoyCeffEL9+vXvuZ63tzeffPIJH330EStXrkSv1+Pm5kZUVBSPPPJIhWsgw4cP57vvvmPw4MF4enri7+9vqHHRokXMnTsXOzs7VCoV77zzDg4ODvTr149Zs2Zhb2/PG2+8wbRp05gyZQoqlQoXFxfWrl1b6Sm2uXPn8s477/DRRx9hY2PDSy+9RMuWLauxlUVNJKPxCiGEqBY5hSWEEKJaJECEEEJUiwSIEEKIapEAEUIIUS0SIEIIIapFAkQIIUS1SIAIIYSoFgkQIYQQ1fL/AdmiNHqiMuqIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nClus = range(1, 20, 2)\n",
    "kmeans = [KMeans(n_clusters=i, random_state= 1995) for i in nClus]\n",
    "scaler = RobustScaler()\n",
    "\n",
    "score = [kmeans[i].fit(clus[probs]).score(clus[probs]) for i in range(len(kmeans))]\n",
    "\n",
    "plt.plot(nClus,score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 7 , random_state = 1995 )\n",
    "kmeans.fit(clus[probs])\n",
    "\n",
    "\n",
    "# Predicting the clusters\n",
    "labels = kmeans.predict(clus[probs])\n",
    "labelsT = kmeans.predict(test[probs])\n",
    "\n",
    "df['clusters'] = labels\n",
    "test['clusters'] = labelsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters'] = df['clusters'].apply(lambda x : str(x))\n",
    "test['clusters'] = test['clusters'].apply(lambda x : str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceros = np.zeros(len(test))\n",
    "for i in [0,1,2,3,5]:\n",
    "    name = [f\"clusters_{i}\"]\n",
    "    test[name[0]] = ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Para train tenemos : (260601, 43), y para test: (86868, 43)\n"
     ]
    }
   ],
   "source": [
    "print(f\" Para train tenemos : {df.shape}, y para test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second models: Evaluating and comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiar a stratifiedkfolds, realizar variables del excel, cambiar numero de clusters a 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5: Choosing best model, version management and reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6: Preparing for production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7: Deploying to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8: Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Treveil, M. & the Dataiku Team. (2020). Introducing MLOps (1.a ed., Vol. 1). O’Reilly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Zheng, A., & Casari, A. (2018). Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists. O’Reilly Media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Hunter, J., Dale, D., Firing, E., Droettboom, M., & The Matplotlib development team. (2002-2021). Matplotlib. Matplotlib 3.5.1 documentation. \n",
    "    https://matplotlib.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    scikit-learn: machine learning in Python — scikit-learn 1.0.2 documentation. (2021). Scikit-Learn. \n",
    "    https://scikit-learn.org/stable/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Wikipedia contributors. (2021, 12 septiembre). Out-of-bag error. Wikipedia. https://en.wikipedia.org/wiki/Out-of-bag_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (2019). Richter’s Predictor: Modeling Earthquake Damage. DrivenData. https://www.drivendata.org/competitions/57/nepal-earthquake/page/136/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Wikipedia contributors. (2022, 16 enero). Random forest. Wikipedia. https://en.wikipedia.org/wiki/Random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Cross-validation: evaluating estimator performance. (2021). Scikit-Learn. https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GitHub - 21zhouyun/CountMinSketch: A simple python implementation of count min sketch. (2016). GitHub. https://github.com/21zhouyun/CountMinSketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint\n",
    "df.to_csv(\"../data/trainProb.csv\", index = False)\n",
    "test.to_csv(\"../data/testProb.csv\", index = False)\n",
    "\n",
    "#dfOut.to_csv(\"../data/trainOutProb.csv\", index = False)\n",
    "#testOut.to_csv(\"../data/testOutProb.csv\", index = False)\n",
    "\n",
    "#df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "#test = pd.read_csv(\"../data/testProb.csv\")\n",
    "\n",
    "#dfOut = pd.read_csv(\"../data/trainOutProb.csv\")\n",
    "#testOut = pd.read_csv(\"../data/testOutProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'damage_grade' \n",
    "numeric = [\"area_percentage_pt\", \"height_percentage_pt\",'prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "dummies = ['count_families_0','count_families_1','count_families_2',\n",
    "                'count_floors_pre_eq_1','count_floors_pre_eq_2',\n",
    "                'foundation_type_1', 'ground_floor_type_1',\n",
    "                'land_surface_condition_t','land_surface_condition_n',\n",
    "                'other_floor_type_j','other_floor_type_q', 'other_floor_type_x', \n",
    "                'position_s','position_t',\n",
    "                'roof_type_n','roof_type_q',\n",
    "                'clusters_0', 'clusters_1', 'clusters_2', 'clusters_3', 'clusters_4','clusters_5', 'clusters_6']\n",
    "\n",
    "binary = ['has_secondary_use',\n",
    "        'has_secondary_use_agriculture',\n",
    "        'has_superstructure_adobe_mud',\n",
    "        'has_superstructure_cement_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_stone',\n",
    "        'has_superstructure_timber']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de072921dc87486613898b1ef56959cc98c50a630fb49de1898fb32d92a683cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
