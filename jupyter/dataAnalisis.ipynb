{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nepal earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Manuel Berea Arellano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 0: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Drivendata] competition: \n",
    "\n",
    "Richter's Predictor: Modeling Earthquake Damage  https://www.drivendata.org/competitions/57/nepal-earthquake/page/134/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        DATA\n",
    "# ==================== #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "#      PLOTING\n",
    "# ============================== #\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#      CLUSTERING\n",
    "# ============================== #\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#      PRE PROCESSING\n",
    "# ============================== #\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "#      METRICS\n",
    "# ============================== #\n",
    "from sklearn.metrics import f1_score   # average='micro'\n",
    "from sklearn.model_selection import cross_val_score , StratifiedShuffleSplit , RepeatedStratifiedKFold\n",
    "\n",
    "#      MODEL SELECTION\n",
    "# ============================== #\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "#      CLASIFICATORS\n",
    "# ============================== #\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#      OTHERS\n",
    "# ============================== #\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "\n",
    "import python.functions\n",
    "from python.KMeansFeaturer import KMeansFeaturizer\n",
    "\n",
    "\n",
    "\n",
    "#      WARNINGS\n",
    "# ============================== #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')\n",
    "#dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t): \n",
    "    \"\"\"\n",
    "    Utilizamos la funcion para apilar listas\n",
    "    \"\"\"\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplots_algorithms(results, names):\n",
    "    \"\"\" \n",
    "    For plot the results\n",
    "    \n",
    "    Para plotear los resultados \n",
    "    Input\n",
    "    --------\n",
    "    results (Pandas DF): Results of training models\n",
    "    names: Names of the models\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Image in the notebook\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.boxplot(results)\n",
    "    plt.xticks(range(1,len(names)+1), names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_reshape(img):\n",
    "    \"\"\"\n",
    "    For show a image.\n",
    "    Para mostrar una imagen.\n",
    "\n",
    "    Input\n",
    "    --------\n",
    "    img (String): path image\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Image in the notebook\n",
    "\n",
    "    \"\"\"\n",
    "    img = Image.open('./images/'+img).convert('RGB')\n",
    "    img = img.resize((300,500))\n",
    "    img = np.asarray(img)\n",
    "    return img\n",
    "\n",
    "def img_reshape_more(img):\n",
    "    \"\"\"\n",
    "    For show a image.\n",
    "    Para mostrar una imagen.\n",
    "\n",
    "    Input\n",
    "    --------\n",
    "    img (String): path image\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Image in the notebook\n",
    "\n",
    "    \"\"\"\n",
    "    img = Image.open('./images/'+img).convert('RGB')\n",
    "    img = img.resize((1000,500))\n",
    "    img = np.asarray(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities(df, test, n): \n",
    "    \"\"\"\n",
    "    Calculate probabilities for distinc geo level and target groups.\n",
    "    Calcular las probabilidades para los distintos geo level y grupos de la target.\n",
    "\n",
    "    Input\n",
    "    --------\n",
    "    df (DataFrame pandas)\n",
    "    n (Int): values 1,2,3 for distinct geo level\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    Dataframe with probabilities new columns\n",
    "    \n",
    "    \"\"\"\n",
    "    column = [f\"geo_level_{n}_id\"]\n",
    "    nom1 = [f\"prob1_geo{n}\"]\n",
    "    nom2 = [f\"prob2_geo{n}\"]\n",
    "    nom3 = [f\"prob3_geo{n}\"]\n",
    "    #This will save the probabilities in one column for each in df and dfOut\n",
    "    damage1 = dict()\n",
    "    damage2 = dict()\n",
    "    damage3 = dict()\n",
    "\n",
    "    for i, j in df[column].value_counts().iteritems():\n",
    "        n1 = len(df[df.damage_grade == 1][df[column[0]] == i])\n",
    "        n2 = len(df[df.damage_grade == 2][df[column[0]] == i])\n",
    "        n3 = len(df[df.damage_grade == 3][df[column[0]] == i])\n",
    "\n",
    "        damage1[i[0]] = n1/j\n",
    "        damage2[i[0]] = n2/j\n",
    "        damage3[i[0]] = n3/j\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "\n",
    "    for i in df[column[0]]:\n",
    "        list1.append(damage1.get(i))\n",
    "        list2.append(damage2.get(i))\n",
    "        list3.append(damage3.get(i))\n",
    "\n",
    "    df[nom1[0]] = list1\n",
    "    df[nom2[0]] = list2\n",
    "    df[nom3[0]] = list3\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "\n",
    "    for i in test[column[0]]:\n",
    "        list1.append(damage1.get(i))\n",
    "        list2.append(damage2.get(i))\n",
    "        list3.append(damage3.get(i))\n",
    "\n",
    "    test[nom1[0]] = list1\n",
    "    test[nom2[0]] = list2\n",
    "    test[nom3[0]] = list3\n",
    "    \n",
    "    return df , test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "A model is trained using  of the folds as training data;\n",
    "\n",
    "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. \n",
    "\n",
    "Extratree classifier is a type of Random forest Classifier, the diference is the randomness goes one step further in the war splits are computed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the performance of our algorithms, we'll use the F1 score which balances the precision and recall of a classifier. Traditionally, the F1 score is used to evaluate performance on a binary classifier, but since we have three possible labels we will use a variant called the micro averaged F1 score. \n",
    "\n",
    "$$ F_{micro} = \\frac{ 2 \\cdot P_{micro} \\cdot R_{micro} }{P_{micro} + R_{micro}} $$\n",
    "\n",
    "where \n",
    "$$ P_{micro} = \\frac{\\sum TP_k}{\\sum (TP_k + FP_k)}, \\ with \\ k=1,2,3 $$\n",
    "and\n",
    "$$ R_{micro} = \\frac{\\sum TP_k}{\\sum (TP_k + FN_k)}, \\ with \\ k=1,2,3 $$\n",
    "\n",
    "$TP$ is true positive, $FP$ is False positive, $FN$ is False negative.\n",
    "\n",
    "In python, you can use f_score with average ='micro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out-of-bag error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-bag (OOB) error, also called out-of-bag estimate, is a method of measuring the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging). Bagging uses subsampling with replacement to create training samples for the model to learn from. OOB error is the mean prediction error on each training sample xi, using only the trees that did not have xi in their bootstrap sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset mainly consists of information on the buildings' structure and their legal ownership. Each row in the dataset represents a specific building in the region that was hit by Gorkha earthquake.\n",
    "\n",
    "*----*\n",
    "\n",
    "\n",
    "El conjunto de datos principalmente consiste en la información estuctural de los datos y su propietario legal. Cada fila del conjunto de datos representa un edificio concreto en la region donde tuvo lugar el terremoto Gorkha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_values.csv\")\n",
    "trainTar = pd.read_csv(\"../data/train_labels.csv\")\n",
    "\n",
    "test = pd.read_csv(\"../data/test_values.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge on one dataframe because it'll permit a better analysis. For feature engineering, we'll merge test to.\n",
    "\n",
    "*----*\n",
    "\n",
    "Unimos en un solo dataframe ya que nos permite un mejor analisis de la target. Para las distintas transformaciones también tendremos que unir el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.merge(trainTar , on= \"building_id\" , how= \"left\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {} rows and {} columns \\n  -Categorical: 8 \\n  -Binary: 22 \\n  -Integer: 6 \".format(len(df) , len(df.columns)))\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Tenemos {} filas y {} columns \\n  -Categoricas: 8 \\n  -Binarias: 22 \\n  -Enetero: 6 \".format(len(df) , len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} rows duplicated\".format(len(df) - df.duplicated().value_counts().values[0]))\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Hay {} filas duplicadas\".format(len(df) - df.duplicated().value_counts().values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} nan values\".format(df.isna().sum().sum()))\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Hay {} valores nulos\".format(df.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not nan values, but we should see if there are wrong values\n",
    "\n",
    "*-----*\n",
    "\n",
    "No hay valores nulos, pero deberíamos mirar si hay errores en algún valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We select only the int columns\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(\"Seleccionamos solo las columnas con dato entero\")\n",
    "df[[\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 0 and 995 value for age column, this is a error value. 0 is it posible but 995 is strange.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vemos como hay valor 0 y 995 en la columna edad, eso es un valor erroneo. 0 es posible, pero 995 es un valor extraño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data = df, y =\"age\" , x=\"damage_grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With boxplot we see that very well. If we won't use robust scaler, we should drop outliers. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Con el boxplot lo podemos ver muy bien. Si no vamos a usar robust scaler, debemos borrar los outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df, x =\"age\" , kind= \"count\" ,  aspect=4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(df[df['age']==995])} values with value 995, i.e {round( 100*len(df[df['age']==995]) / len(df) ,2)} % of total, these probably are unknown values.\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(f\"Hay {len(df[df['age']==995])} valores con 995, i.e {round( 100*len(df[df['age']==995]) / len(df) ,2)} % the total, son probablemente valores desconocidos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the distribution:\n",
    "\n",
    "*-----*\n",
    "\n",
    "Aquí podemos ver la distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['age']==995].groupby(['damage_grade']).count()['building_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop outliers, but in other hand we analize the age in groups and we'll see what is better.\n",
    "It seems that would nice make groups with the age, because there are a lot of outliers, and we can make groups to solve this problem.\n",
    "\n",
    "We'll do this in the next chapter.\n",
    "\n",
    "*----*\n",
    "\n",
    "Vamos a borrar los outliers, pero por otro lado vamos a analizar la edad en grupos y veremos cual es mejor.\n",
    "Parece optimo hacer grupos de edad de los edificiones, porque hay muchos outliers y podemos hacer grupos para resolver este problema.\n",
    "\n",
    "Heremos esto en el proximo capítulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_1 = df.describe().loc['25%'].loc['age']\n",
    "Q_3 = df.describe().loc['75%'].loc['age']\n",
    "IQR = Q_3 - Q_1\n",
    "df['outliers'] = df['age'].apply( lambda x : 1 if ((x < (Q_1 - 1.5*IQR) ) or ( (Q_3 + 1.5 * IQR) < x ) ) else 0 )\n",
    "print(f\"There are {df['outliers'].sum()} outliers, i.e {round( 100*df['outliers'].sum() / len(df) , 2 )} % of total, we are going to drop it\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(f\"Hay {df['outliers'].sum()} outliers, es un {round( 100*df['outliers'].sum() / len(df) , 2 )} % del total, vamos a sacarlos del estudio\")\n",
    "dfOut = df[df['outliers'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data = dfOut, y =\"age\" , x=\"damage_grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = dfOut, x =\"age\" , kind= \"count\" ,  aspect=4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOut[[\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to see \"area_percentage\" and \"height_percentage\", because it seems like there are outliers too.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vamos a ver la columna \"area_percentage\" y \"height_percentage\", porque parece que también tiene outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfOut[[\"area_percentage\", \"height_percentage\"]].describe())\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "fig.suptitle(\"Area and Height percentage boxplot\")\n",
    "#-----#\n",
    "ax1.set_title(\"Area percentage\")\n",
    "ax1.boxplot(dfOut[[\"area_percentage\"]])\n",
    "#-----#\n",
    "ax2.set_title(\"Hight percentage\")\n",
    "ax2.boxplot(dfOut[[\"height_percentage\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these columns, probably the best idea is use a robust scaler, because 100% value is posible and don't seems an unknown value.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Para estas columns, probablemente la mejor idea es usar un robust scaler, porque el valor 100% es posible y no parece un valor desconocido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before outliers analysis we have:\n",
    "\n",
    "*------*\n",
    "\n",
    "Después del analisis de outliers tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We drop outlierns, now we have {round (100 - len(dfOut)*100 / len(df) ,2)} % less rows than the initial dataframe.\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - -\")\n",
    "print(f\"Hemos borrado outliers, ahora tenemos un {round (100 - len(dfOut)*100 / len(df) ,2)} % menos filas que el dataframe original.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrTot = df[numeric].corr()\n",
    "corrOut = dfOut[numeric].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the diferences between corrTot and corrOut\n",
    "\n",
    "*-----*\n",
    "\n",
    "Aqui vemos las diferencias entra ambas correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(corrTot-corrOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to analize only the corrTot, because the diferences are minimun.\n",
    "\n",
    "*------*\n",
    "\n",
    "Vamos a analizar la correlacion solo de corrTot, porque las diferencias son mínimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORPLOT\n",
    "plt.figure(figsize=(8, 9))\n",
    "maskTot = np.triu(np.ones_like(corrTot, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corrTot, mask=maskTot, cmap=cmap, vmax=.3, center=0, annot= True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .8} )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest correlation is between number floors pre earthquake and the porcent height. But 0.77 is not enought for drop the column.\n",
    "\n",
    "*------*\n",
    "\n",
    "La correlación más alta es entre numero de plantas antes del terremoto y el porcentaje de altura. Pero 0.77 no es suficiente para borrar la columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Featuring Engineering and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['land_surface_condition','foundation_type','roof_type','ground_floor_type','other_floor_type','position','plan_configuration','legal_ownership_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Land surface condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface condition of the land where the building was built. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Estado de la superficio del terreno donde se contruyó el edificio.\n",
    "\n",
    "\n",
    "Possible values: n, o, t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[0]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[0] , bins=len(set(df[categorical[0]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[0], bins=len(set(df[categorical[0]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[0] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this to analisis, we are going to group the o and n values in one.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Con este analisis, vamos a agrupar los valores o y n en solo uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[0]] = df[categorical[0]].apply(lambda x: 1 if x == 't' else 0)\n",
    "dfOut[categorical[0]] = dfOut[categorical[0]].apply(lambda x: 1 if x == 't' else 0)\n",
    "\n",
    "test[categorical[0]] = test[categorical[0]].apply(lambda x: 1 if x == 't' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[0] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Foundation type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of foundation used while building. \n",
    "\n",
    "*----*\n",
    "\n",
    "Tipo de financiacion usada cuando se contruyó el edificio.\n",
    "\n",
    "Possible values: h, i, r, u, w.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[1]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[1] , bins=len(set(df[categorical[1]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[1], bins=len(set(df[categorical[1]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[1] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[1]] = df[categorical[1]].apply(lambda x : 1 if x == 'r' else 0)\n",
    "dfOut[categorical[1]] = dfOut[categorical[1]].apply(lambda x : 1 if x == 'r' else 0)\n",
    "\n",
    "test[categorical[1]] = test[categorical[1]].apply(lambda x : 1 if x == 'r' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[1] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roof type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of roof used while building. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Tipo de tejado empleado al construir el edificio\n",
    "\n",
    "Possible values: n, q, x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[2]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[2] , bins=len(set(df[categorical[2]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[2], bins=len(set(df[categorical[2]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[2] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[2]] = df[categorical[2]].apply(lambda x : 1 if x == 'q' else 0)\n",
    "dfOut[categorical[2]] = dfOut[categorical[2]].apply(lambda x : 1 if x == 'q' else 0)\n",
    "\n",
    "test[categorical[2]] = test[categorical[2]].apply(lambda x : 1 if x == 'q' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[2] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ground floor type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of the ground floor. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Tipo de suelo.\n",
    "\n",
    "Possible values: f, m, v, x, z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[3]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[3] , bins=len(set(df[categorical[3]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[3], bins=len(set(df[categorical[3]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[3]] = df[categorical[3]].apply(lambda x : 'other' if x == 'z' else 'other' if x == 'm' else x)\n",
    "dfOut[categorical[3]] = dfOut[categorical[3]].apply(lambda x : 'other' if x == 'z' else 'other' if x == 'm' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[3]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "sns.catplot(data= df , x = categorical[3] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[3]] = df[categorical[3]].apply(lambda x : 1 if x == 'f' else 0)\n",
    "dfOut[categorical[3]] = dfOut[categorical[3]].apply(lambda x : 1 if x == 'f' else 0)\n",
    "\n",
    "test[categorical[3]] = test[categorical[3]].apply(lambda x : 1 if x == 'f' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[3] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other floor type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Type of constructions used in higher than the ground floors (except of roof). \n",
    " \n",
    " *-----*\n",
    "\n",
    " Tipo de materiales usados en plantas superiores distintas a la baja y techo.\n",
    " \n",
    " Possible values: j, q, s, x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[4]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[4] , bins=len(set(df[categorical[4]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[4], bins=len(set(df[categorical[4]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[4] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[4]] = df[categorical[4]].apply(lambda x : 'j' if x == 's' else x)\n",
    "dfOut[categorical[4]] = dfOut[categorical[4]].apply(lambda x : 'j' if x == 's' else x)\n",
    "\n",
    "test[categorical[4]] = test[categorical[4]].apply(lambda x : 'j' if x == 's' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[4]] = df[categorical[4]].apply(lambda x : 2 if x == 'q' else 1 if x == 'x' else  0)\n",
    "dfOut[categorical[4]] = dfOut[categorical[4]].apply(lambda x : 2 if x == 'q' else 1 if x == 'x' else  0)\n",
    "\n",
    "test[categorical[4]] = test[categorical[4]].apply(lambda x : 2 if x == 'q' else 1 if x == 'x' else  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[4] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position of the building. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Posición del edificio.\n",
    "\n",
    "Possible values: j, o, s, t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[5]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[5] , bins=len(set(df[categorical[5]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[5], bins=len(set(df[categorical[5]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[5] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[5]] = df[categorical[5]].apply(lambda x : 1 if x == 's' else 0)\n",
    "dfOut[categorical[5]] = dfOut[categorical[5]].apply(lambda x : 1 if x == 's' else 0)\n",
    "\n",
    "test[categorical[5]] = test[categorical[5]].apply(lambda x : 1 if x == 's' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[5] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plan configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building plan configuration. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Configuración del plano del edificio.\n",
    "\n",
    "Possible values: a, c, d, f, m, n, o, q, s, u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[6]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[6] , bins=len(set(df[categorical[6]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[6], bins=len(set(df[categorical[6]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[6] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical[6]] = df[categorical[6]].apply(lambda x : 1 if x == 'd' else 0)\n",
    "dfOut[categorical[6]] = dfOut[categorical[6]].apply(lambda x : 1 if x == 'd' else 0)\n",
    "\n",
    "test[categorical[6]] = test[categorical[6]].apply(lambda x : 1 if x == 'd' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = categorical[6] , kind= 'count', hue = 'damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column is not well clustered, we are going to drop it\n",
    "\n",
    "*----*\n",
    "\n",
    "Esta columna no está bien repartida, vamos a eliminarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(categorical[6], axis = 1)\n",
    "dfOut = dfOut.drop(categorical[6], axis = 1)\n",
    "\n",
    "test = test.drop(categorical[6], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Legal ownership status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal ownership status of the land where building was built. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Situación de la propiedad legal del terreno donde se construyó el edificio. \n",
    "\n",
    "\n",
    "Possible values: a, r, v, w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(df.groupby(categorical[7]).count()['building_id'] *100 / len(df) ,2 ) )\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "ax1.hist(data = df , x = categorical[7] , bins=len(set(df[categorical[7]])))\n",
    "ax1.set_title(\"Dataframe total\")\n",
    "ax2.hist(data = dfOut , x = categorical[7], bins=len(set(df[categorical[7]])))\n",
    "ax2.set_title(\"Dataframe without outliers\")\n",
    "plt.suptitle(categorical[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(categorical[7], axis = 1)\n",
    "dfOut = dfOut.drop(categorical[7], axis = 1)\n",
    "\n",
    "test = test.drop(categorical[7], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). \n",
    "\n",
    "\n",
    "*-----*\n",
    "\n",
    "\n",
    "Region geográfica en donde hay edificios, del más grande (level 1) al mas especifico, sub region (level 3).\n",
    "\n",
    "Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2]:\n",
    "    print(\"\\n- - - - - - - \")\n",
    "    with pd.option_context('display.max_rows',10):\n",
    "        print(df[geos[i]].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the probability of belonging to one target group or another based on the geo level columns. This will help us to cluster the diferent positions.\n",
    "\n",
    "*-------*\n",
    "\n",
    "Vamos a calcular la probabilidad de pertenecer a un grupo de la target u otro en función de las columnas de geo level. Esto nos ayudará a relacionar las distintas posiciones y clusterizarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, test = probabilities(df,test,1)\n",
    "df, test = probabilities(df,test,2)\n",
    "df, test = probabilities(df,test,3)\n",
    "\n",
    "#df.to_csv(\"../data/trainProb.csv\")\n",
    "#test.to_csv(\"../data/testProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOut, testOut = probabilities(dfOut,test,1)\n",
    "dfOut, testOut = probabilities(dfOut,test,2)\n",
    "dfOut, testOut = probabilities(dfOut,test,3)\n",
    "\n",
    "#dfOut.to_csv(\"../data/trainOutProb.csv\")\n",
    "#testOut.to_csv(\"../data/testOutProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "#test = pd.read_csv(\"../data/testProb.csv\")\n",
    "\n",
    "#dfOut = pd.read_csv(\"../data/trainOutProb.csv\")\n",
    "#testOut = pd.read_csv(\"../data/testOutProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = ['prob1_geo1','prob2_geo1', 'prob3_geo1', 'prob1_geo2', 'prob2_geo2', 'prob3_geo2','prob1_geo3', 'prob2_geo3', 'prob3_geo3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClus = range(3, 10)\n",
    "kmeans = [KMeans(n_clusters=i, random_state= 1995) for i in nClus]\n",
    "\n",
    "score = [kmeans[i].fit(df[probs]).score(df[probs]) for i in range(len(kmeans))]\n",
    "\n",
    "plt.plot(nClus,score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seen the plot, I'll choose 5 clusters.\n",
    "\n",
    "*-------*\n",
    "\n",
    "Viendo el gráfico, voy a escoger 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5 , random_state = 1995 )\n",
    "kmeans.fit(df[probs])\n",
    "\n",
    "# Predicting the clusters\n",
    "labels = kmeans.predict(df[probs])\n",
    "labelsT = kmeans.predict(test[probs])\n",
    "\n",
    "df['clusters'] = labels\n",
    "test['clusters'] = labelsT\n",
    "\n",
    "# *-----*\n",
    "\n",
    "kmeans = KMeans(n_clusters = 5 , random_state = 1995 )\n",
    "kmeans.fit(dfOut[probs])\n",
    "\n",
    "# Predicting the clusters\n",
    "labels = kmeans.predict(dfOut[probs])\n",
    "labelsT = kmeans.predict(testOut[probs])\n",
    "\n",
    "dfOut['clusters'] = labels\n",
    "testOut['clusters'] = labelsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data= df , x = \"clusters\" , kind=\"count\" , hue= \"damage_grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to analize the binary columns.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Finalmente vamos a analizar las columnas de valor binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = ['has_secondary_use','has_secondary_use_agriculture','has_secondary_use_gov_office','has_secondary_use_health_post',\n",
    "            'has_secondary_use_hotel','has_secondary_use_industry','has_secondary_use_institution','has_secondary_use_other',\n",
    "            'has_secondary_use_rental','has_secondary_use_school','has_secondary_use_use_police','has_superstructure_adobe_mud',\n",
    "            'has_superstructure_bamboo','has_superstructure_cement_mortar_brick','has_superstructure_cement_mortar_stone', \n",
    "            'has_superstructure_mud_mortar_brick', 'has_superstructure_mud_mortar_stone', 'has_superstructure_other', \n",
    "            'has_superstructure_rc_engineered','has_superstructure_rc_non_engineered', 'has_superstructure_stone_flag', 'has_superstructure_timber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\t% of 1 in the columns\")\n",
    "print(\"\\t- - - - - - - - - - - - - - - - - - - \")\n",
    "print(\"\\t\\t% de 1 en las columnas\")\n",
    "round(df[binary].sum() *100 / len(df) , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = list()\n",
    "for x in binary:\n",
    "    if (round(df[x].sum() *100 / len(df) , 2) < 10.0) == True:\n",
    "        dp.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = df.drop(dp, axis=1)\n",
    "dfOut_mod = dfOut.drop(dp, axis=1)\n",
    "test_mod = test.drop(dp, axis=1)\n",
    "testOut_mod = testOut.drop(dp, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model, we'll use:\n",
    "\n",
    "*------*\n",
    "\n",
    "Para el primer modelo, vamos a usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\"count_floors_pre_eq\", \"age\" , \"area_percentage\" , \"height_percentage\", \"count_families\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count floors pre earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of floors in the building before the earthquake.\n",
    "\n",
    "*------*\n",
    "\n",
    "Numero de plantas del edificio pre terremoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[0] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric[0]] = df[numeric[0]].apply(lambda x: x if x<3 else 3)\n",
    "dfOut[numeric[0]] = dfOut[numeric[0]].apply(lambda x: x if x<3 else 3)\n",
    "test[numeric[0]] = test[numeric[0]].apply(lambda x: x if x<3 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[0] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age of the building in years.\n",
    "\n",
    "*------*\n",
    "\n",
    "Edad del edificio en años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = dfOut , x = numeric[1] , kind= 'count', hue='damage_grade', height=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOut[numeric[1]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs robust scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized area and height of the building footprint.\n",
    "\n",
    "*------*\n",
    "\n",
    "Superficie y altura normalizadas de la huella del edificio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Families"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of families that live in the building.\n",
    "\n",
    "*-------*\n",
    "\n",
    "Numero de familias que viven en el edificio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[4] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric[4]] = df[numeric[4]].apply(lambda x: x if x<2 else 2)\n",
    "dfOut[numeric[4]] = dfOut[numeric[4]].apply(lambda x: x if x<2 else 2)\n",
    "test[numeric[4]] = test[numeric[4]].apply(lambda x: x if x<2 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df , x = numeric[4] , kind= 'count', hue='damage_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First models: Evaluating and comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'damage_grade'\n",
    "numeric = [ \"age\" ,'prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "categorical = ['clusters','roof_type',\"area_percentage\" , \"height_percentage\",\"count_floors_pre_eq\", \"count_families\",'foundation_type','ground_floor_type','has_secondary_use','has_superstructure_mud_mortar_stone','has_superstructure_timber','land_surface_condition','other_floor_type','position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_mod.columns) - set([target]) - set(numeric) - set(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escaler = RobustScaler().fit(df[numeric])\n",
    "escalerOut = RobustScaler().fit(dfOut[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric] = escaler.transform(df[numeric])\n",
    "test[numeric] = escaler.transform(test[numeric])\n",
    "\n",
    "dfOut[numeric] = escalerOut.transform(dfOut[numeric])\n",
    "testOut[numeric] = escalerOut.transform(testOut[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = df_split(df.drop(columns = [target,'outliers']), df[target],random_state = 1995)\n",
    "X_trainO, X_testO, y_trainO, y_testO = df_split(dfOut.drop(columns = [target,'outliers']), dfOut[target],random_state = 1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare distinct models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compare the distinct type of classifiers for select the better options and for each selected model do hyperparameter tunning.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vamos a comparar los distintos tipos de clasificadores para seleccionar la mejor option y para cada uno de estos hacer el tuneado de los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1995\n",
    "models = []\n",
    "models.append(('LR'     , LogisticRegression(random_state=seed)))\n",
    "models.append(('LDA'    , LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN'    , KNeighborsClassifier()))\n",
    "models.append(('DTC'    , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('NB'     , GaussianNB()))\n",
    "models.append(('RFC'    , RandomForestClassifier(random_state=seed)))\n",
    "models.append(('EXT'    , ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('LGBM'   , LGBMClassifier(random_state=seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "metric = 'f1_micro'\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    cv_results = cross_val_score(model, X_trainO, y_trainO, cv =5, scoring = metric)\n",
    "\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "boxplots_algorithms(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1995\n",
    "models = []\n",
    "models.append(('LDA'    , LinearDiscriminantAnalysis()))\n",
    "models.append(('RFC'    , RandomForestClassifier(random_state=seed)))\n",
    "models.append(('EXT'    , ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('LGBM'   , LGBMClassifier(random_state=seed)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "metric = 'f1_micro'\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    cv_results = cross_val_score(model, X_trainO, y_trainO, cv =5, scoring = metric)\n",
    "\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "boxplots_algorithms(results, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear discriminant analysis is the most easy way to explain the models. We can get the coefs and with this coefs explain the predictions.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Analisis discriminantes es la forma más fácil de explicar modelos. Ya que nos devuelve los distintos coeficientes que nos ayudan a explicar las prediccioes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'solver' : ['svd', 'lsqr', 'eigen'] \n",
    "}\n",
    "\n",
    "CVLRmodel = LinearDiscriminantAnalysis()\n",
    "\n",
    "gridLDA = GridSearchCV( estimator = CVLRmodel,\n",
    "                        param_grid = param,\n",
    "                        scoring = 'f1_micro',\n",
    "                        n_jobs = -1,\n",
    "                        refit = True,\n",
    "                        cv = 5,\n",
    "                        verbose = 1,\n",
    "                        return_train_score = True)\n",
    "\n",
    "gridLDA.fit(X_trainO,y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionesLDA = gridLDA.predict(X = X_testO)\n",
    "\n",
    "f1score0 = f1_score(\n",
    "        y_true  = y_testO,\n",
    "        y_pred  = prediccionesLDA,\n",
    "        average = 'micro'\n",
    "    )\n",
    "\n",
    "print(f\"El f1 score de test es: {round(f1score0,3)} con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = testOut.copy()\n",
    "\n",
    "prediccionesLDA = gridLDA.predict(test_copy)\n",
    "test_copy['damage_grade'] = prediccionesLDA\n",
    "test_copy[['building_id','damage_grade']].to_csv(\"../predictions/predLDAmodel1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took 0.7203 score in drivenData platform. Now we have try with the other models.\n",
    "\n",
    "*----*\n",
    "\n",
    "Obtuve 0.7203 de score en la plataforma de drivenData. Ahora vamos a probar con otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = RandomForestClassifier(\n",
    "            n_estimators = 150,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 'auto',\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)\n",
    "\n",
    "\n",
    "modeloOut = RandomForestClassifier(\n",
    "            n_estimators = 150,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 'auto',\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(X_train, y_train) , modeloOut.fit(X_trainO, y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo inicial\n",
    "# ==============================================================================\n",
    "predicciones = modelo.predict(X = X_test)\n",
    "\n",
    "f1score1 = f1_score(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        average = 'micro'\n",
    "       )\n",
    "print(f\"El f1 score de test es: {round(f1score1,3)} con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.copy()\n",
    "testOut1 = testOut.copy()\n",
    "\n",
    "\n",
    "predicciones = modelo.predict(test1)\n",
    "test['damage_grade'] = predicciones\n",
    "test[['building_id','damage_grade']].to_csv(\"../predictions/predETCmodel1.csv\", index = False)\n",
    "\n",
    "\n",
    "prediccionesOut = modeloOut.predict(testOut1)\n",
    "testOut['damage_grade'] = prediccionesOut\n",
    "testOut[['building_id','damage_grade']].to_csv(\"../predictions/predOutETCmodel1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a first point to improve. The next steps are:\n",
    "    \n",
    "    - Tunning the model\n",
    "  \n",
    "    - Compare with other algorithms\n",
    "  \n",
    "    - Improve our featuring engineering, for exmple, changing the clustering.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model with outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/one.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/oneOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tunning: Num estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a loop for training the diferent models with each n_estimador value and take train error and Out-of Bag value. It'll permit us choose the best parameter option for our dataframe.\n",
    "It's important choose the less number of trees with the best score, more trees wont improve our power prediction but it will make us don't have the best performance.\n",
    "\n",
    "*------*\n",
    "\n",
    "Vamos a utilizar un bucle para entrenar los diferentes moderlos con cada uno de los valores de los estimadores y cogeremos el error y el valor Out.of-bag. Esto nos va a permitir elegir la mejor opcion de parámetros para nuestro conjunto de datos. Es importante elegir el menor número de árboles con el mayor score, más arboles no implica mayor poder predictivo, pero si que hará empeorar nuestro performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "oob_scores   = []\n",
    "\n",
    "estimator_range = range(1, 200, 25)\n",
    "\n",
    "# Loop for training models with each n_estimator value and take\n",
    "# train error and Out-of-Bag value.\n",
    "for n_estimators in estimator_range:\n",
    "    model = RandomForestClassifier(\n",
    "                n_estimators = n_estimators,\n",
    "                criterion    = 'gini',\n",
    "                max_depth    = 10,\n",
    "                max_features = 'auto',\n",
    "                bootstrap    = True,\n",
    "                oob_score    = True,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 1995\n",
    "             )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    train_scores.append(model.score(X_train, y_train))\n",
    "    oob_scores.append(model.oob_score_)\n",
    "    \n",
    "# Graph for analize the error\n",
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "ax.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "ax.plot(estimator_range, oob_scores, label=\"out-of-bag scores\")\n",
    "ax.plot(estimator_range[np.argmax(oob_scores)], max(oob_scores),\n",
    "        marker='o', color = \"red\", label=\"max score\")\n",
    "ax.set_xlabel(\"n_estimators\")\n",
    "ax.set_title(\"Evolution out-of-bag-error vs num estimators\")\n",
    "plt.legend();\n",
    "print(f\"Best value of n_estimators: {estimator_range[np.argmax(oob_scores)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use cross validation with f1 score. \n",
    "\n",
    "*-----*\n",
    "\n",
    "Ahora vamos a utilizar cross validation con la métrica f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV validation\n",
    "# ==============================================================================\n",
    "estimator_range = range(1, 100, 20)\n",
    "cv_scores = []\n",
    "for n_estimators in estimator_range:\n",
    "    \n",
    "    modelo = RandomForestClassifier(\n",
    "                n_estimators = n_estimators,\n",
    "                criterion    = 'gini',\n",
    "                max_depth    = 10,\n",
    "                max_features = 'auto',\n",
    "                bootstrap    = True,\n",
    "                oob_score    = True,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 1995\n",
    "             )\n",
    "    scores = cross_val_score(\n",
    "                estimator = modelo,\n",
    "                X         = X_train,\n",
    "                y         = y_train,\n",
    "                scoring   = 'f1_micro',\n",
    "                cv        = 5\n",
    "             )   \n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "print(f\"Best value of n_estimators: {estimator_range[np.argmax(cv_scores)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should take around 50 and 60 trees.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Debemos coger entre 50 y 60 árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tunning: Max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV validation\n",
    "# ==============================================================================\n",
    "max_features_range = range(1, X_train.shape[1] + 1, 1)\n",
    "cv_scores = []\n",
    "for max_features in max_features_range:\n",
    "    \n",
    "    modelo = RandomForestClassifier(\n",
    "                n_estimators = 55,\n",
    "                criterion    = 'gini',\n",
    "                max_depth    = 10,\n",
    "                max_features = max_features,\n",
    "                bootstrap    = True,\n",
    "                oob_score    = True,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 1995\n",
    "             )\n",
    "    scores = cross_val_score(\n",
    "                estimator = modelo,\n",
    "                X         = X_train,\n",
    "                y         = y_train,\n",
    "                scoring   = 'f1_micro',\n",
    "                cv        = 5\n",
    "             )   \n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "    \n",
    "print(f\"Best value of n_estimators: {max_features_range[np.argmax(cv_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSte = RandomForestClassifier(\n",
    "            n_estimators = 55,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 46,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)\n",
    "\n",
    "\n",
    "modeloSteOut = RandomForestClassifier(\n",
    "            n_estimators = 55,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 46,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSte.fit(X_train, y_train) , modeloSteOut.fit(X_trainO, y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo inicial\n",
    "# ==============================================================================\n",
    "predicciones = modeloSte.predict(X = X_test)\n",
    "\n",
    "f1score1 = f1_score(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        average = 'micro'\n",
    "       )\n",
    "print(f\"El f1 score de test es: {f1score1} con outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.copy()\n",
    "testOut1 = testOut.copy()\n",
    "\n",
    "predicciones = modeloSte.predict(test1)\n",
    "test['damage_grade'] = predicciones\n",
    "test[['building_id','damage_grade']].to_csv(\"../predictions/predETCmodel2.csv\", index = False)\n",
    "\n",
    "\n",
    "prediccionesOut = modeloSteOut.predict(testOut1)\n",
    "testOut['damage_grade'] = prediccionesOut\n",
    "testOut[['building_id','damage_grade']].to_csv(\"../predictions/predOutETCmodel2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/twoOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tunning: Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "# ==============================================================================\n",
    "param_grid = {'n_estimators': [50,55,60],\n",
    "              'max_features': [46,None],\n",
    "              'max_depth'   : [None, 3,5,10],\n",
    "              'criterion'   : ['gini']\n",
    "             }\n",
    "\n",
    "# Grid serach CV \n",
    "# ==============================================================================\n",
    "gridRF = GridSearchCV(\n",
    "        estimator  = RandomForestClassifier(random_state = 1995),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_micro',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1995), \n",
    "        refit      = True,\n",
    "        verbose    = 1,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridRF.fit(X = X_trainO, y = y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloHyperOut = ExtraTreesClassifier(\n",
    "            n_estimators = 50,\n",
    "            criterion    = 'gini',\n",
    "            max_depth    = 10,\n",
    "            max_features = 46,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloHyperOut.fit(X_trainO,y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut2 = testOut.drop(\"damage_grade\",axis=1).copy()\n",
    "\n",
    "prediccionesOut = modeloHyperOut.predict(testOut2)\n",
    "testOut2['damage_grade'] = prediccionesOut\n",
    "testOut2[['building_id','damage_grade']].to_csv(\"../predictions/predOutETCmodel3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/threeOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: LightGBM Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Num estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "f1_scores   = []\n",
    "estimator_range = range(25, 500, 25)\n",
    "# Loop for training models with each n_estimator value and take\n",
    "# train error and f1 score\n",
    "for n_estimators in estimator_range:\n",
    "    model = LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_estimators= n_estimators, \n",
    "                    n_jobs =-1, \n",
    "                    num_leaves=124, \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995)\n",
    "\n",
    "    model.fit(X_trainO, y_trainO)\n",
    "    train_scores.append(model.score(X_trainO, y_trainO))\n",
    "    \n",
    "    predicciones = model.predict(X = X_testO)\n",
    "\n",
    "    f1score1 = f1_score(\n",
    "            y_true  = y_testO,\n",
    "            y_pred  = predicciones,\n",
    "            average = 'micro'\n",
    "        )\n",
    "    f1_scores.append(f1score1)\n",
    "# Graph for analize the error\n",
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "ax.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "ax.plot(estimator_range, f1_scores, label=\"F1 Score\")\n",
    "ax.plot(estimator_range[np.argmax(f1_scores)], max(f1_scores),\n",
    "        marker='o', color = \"red\", label=\"max score\")\n",
    "ax.set_xlabel(\"n_estimators\")\n",
    "ax.set_title(\"Evolution F1 Score vs num estimators\")\n",
    "plt.legend();\n",
    "print(f\"Best value of n_estimators: {estimator_range[np.argmax(f1_scores)]} with f1 score: {max(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try with this num estimators.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Vamos a probar con esta cantidad de estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLGBMOut = LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_estimators= 425, \n",
    "                    n_jobs =-1, \n",
    "                    num_leaves=124, \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLGBMOut.fit(X_trainO,y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut3 = testOut.copy()\n",
    "\n",
    "prediccionesOut = modeloLGBMOut.predict(testOut3)\n",
    "testOut3['damage_grade'] = prediccionesOut\n",
    "testOut3[['building_id','damage_grade']].to_csv(\"../predictions/predOutLGBMmodel1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model without outliers\")\n",
    "pred_model1 = img_reshape_more('/prediccions/threeOut.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Searchgrid CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "# ==============================================================================\n",
    "param_grid = {'n_estimators': [400,425,450],\n",
    "              'num_leaves'  : [10,35,135],\n",
    "              'max_depth'   : [-1,5,10],\n",
    "              'learning_rate':[0.01]\n",
    "             }\n",
    "\n",
    "# Grid serach CV \n",
    "# ==============================================================================\n",
    "gridLGBM = GridSearchCV(\n",
    "        estimator  = LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_jobs =-1,  \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_micro',\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1995), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridLGBM.fit(X = X_trainO, y = y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridLGBM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLGBM =  LGBMClassifier(boosting_type = 'gbdt', \n",
    "                    learning_rate=0.01, \n",
    "                    max_depth=10, \n",
    "                    n_estimators= 450, \n",
    "                    n_jobs =-1, \n",
    "                    num_leaves=135, \n",
    "                    objective='multiclass',\n",
    "                    random_state=1995)\n",
    "\n",
    "modelLGBM.fit(X_trainO, y_trainO)\n",
    "\n",
    "prediccionesLGBM = modelLGBM.predict(X = X_testO)\n",
    "\n",
    "f1score1 = f1_score(\n",
    "        y_true  = y_testO,\n",
    "        y_pred  = prediccionesLGBM,\n",
    "        average = 'micro'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOut4 = testOut.copy()\n",
    "\n",
    "prediccionesLGBM = modelLGBM.predict(testOut4)\n",
    "testOut4['damage_grade'] = prediccionesLGBM\n",
    "testOut4[['building_id','damage_grade']].to_csv(\"../predictions/predOutLGBMmodel2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LGBM hyperparameter tunning\")\n",
    "pred_model1 = img_reshape_more('/prediccions/threeOutLGBMHYPER.jpg')\n",
    "plt.imshow(np.asarray(pred_model1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Featuring Engineering and selection (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to try a better featuring engineering, improving the transformations.\n",
    "\n",
    "*----*\n",
    "\n",
    "Ahora vamos a tratar de mejorar el featuring engineering, mejorando las transformaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "train = pd.read_csv(\"../data/train_values.csv\")\n",
    "trainTar = pd.read_csv(\"../data/train_labels.csv\")\n",
    "df = train.merge(trainTar , on= \"building_id\" , how= \"left\")\n",
    "\n",
    "#Test\n",
    "test = pd.read_csv(\"../data/test_values.csv\")\n",
    "\n",
    "\n",
    "#Probabilities\n",
    "df, test = probabilities(df,test,1)\n",
    "df, test = probabilities(df,test,2)\n",
    "df, test = probabilities(df,test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint\n",
    "#df.to_csv(\"../data/trainProb.csv\", index = False)\n",
    "#test.to_csv(\"../data/testProb.csv\", index = False)\n",
    "\n",
    "#df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "#test = pd.read_csv(\"../data/testProb.csv\")\n",
    "\n",
    "target = 'damage_grade'\n",
    "numeric = [ \"age\" ,\"area_percentage\" , \"height_percentage\",'prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "categorical = ['roof_type',\"count_floors_pre_eq\", \"count_families\",'foundation_type','ground_floor_type','has_secondary_use','has_superstructure_mud_mortar_stone','has_superstructure_timber','land_surface_condition','other_floor_type','position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featuring Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to solve the outliers problem without drop this rows. The steps that I'm going to follow are:\n",
    "- Use power tranformers like (Box-Cox).\n",
    "- Re-category poorly represented groups.\n",
    "- Change kluster number.\n",
    "- Use robust-scaler.\n",
    "  \n",
    "*-----*\n",
    "\n",
    "Vamos a tratar de resolver el problema de los outliers sin eliminar las filas. Los pasos a seguir serán:\n",
    "- Usar power transformer como Box.Cox.\n",
    "- Re-categorizar los grupos mal representados.\n",
    "- Cambiar número de clusters. \n",
    "- Usar robus scaler (o min-max scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see this transformations on gitHub, I'll use it for cluster the geo features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GitHub/ofigue/RichterPrediction](https://github.com/ofigue/RichterPrediction/blob/master/notebooks/Exploration.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CntFloorAge'] = df['count_floors_pre_eq']/(df['age']+0.1)\n",
    "df['CntFloorsArea'] = df['count_floors_pre_eq']/df['area_percentage']\n",
    "df['CntFloorsHeight'] = df['count_floors_pre_eq']/df['height_percentage']\n",
    "df['AreaPerAge'] = df['area_percentage']/(df['age']+0.1)\n",
    "df['HeightPerAge'] = df['height_percentage']/(df['age']+0.1)\n",
    "df['AreaPerHeight'] = df['area_percentage']/df['height_percentage']\n",
    "df['CntFamFloors'] = df['count_families']/df['count_floors_pre_eq']\n",
    "df['CntFamArea'] = df['count_families']/df['area_percentage']\n",
    "df['CntFamHeight'] = df['count_families']/df['height_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['CntFloorAge'] = test['count_floors_pre_eq']/(test['age']+0.1)\n",
    "test['CntFloorsArea'] = test['count_floors_pre_eq']/test['area_percentage']\n",
    "test['CntFloorsHeight'] = test['count_floors_pre_eq']/test['height_percentage']\n",
    "test['AreaPerAge'] = test['area_percentage']/(test['age']+0.1)\n",
    "test['HeightPerAge'] = test['height_percentage']/(test['age']+0.1)\n",
    "test['AreaPerHeight'] = test['area_percentage']/test['height_percentage']\n",
    "test['CntFamFloors'] = test['count_families']/test['count_floors_pre_eq']\n",
    "test['CntFamArea'] = test['count_families']/test['area_percentage']\n",
    "test['CntFamHeight'] = test['count_families']/test['height_percentage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_log'] = df['age'].apply(lambda x : 0 if x<=0 else np.log(x))\n",
    "\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "df['age_pt'] = pt.fit_transform(df[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2 , ax3) = plt.subplots(3,1, figsize =(15,12))\n",
    "df['age'].hist(ax=ax1, bins=50)\n",
    "ax1.tick_params(labelsize=10)\n",
    "ax1.set_xlabel('age', fontsize=10)\n",
    "ax1.set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['age_log'].hist(ax=ax2, bins=50)\n",
    "ax2.tick_params(labelsize=10)\n",
    "ax2.set_xlabel('log10(age))', fontsize=10)\n",
    "ax2.set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['age_pt'].hist(ax=ax3, bins=50)\n",
    "ax3.tick_params(labelsize=10)\n",
    "ax3.set_xlabel('PowerTransform(age))', fontsize=10)\n",
    "ax3.set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems better the log transformation, but we can check against a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, (ax1, ax2 , ax3) = plt.subplots(3,1, figsize =(12,8))\n",
    "prob1 = stats.probplot(df['age'], dist=stats.norm, plot=ax1)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_title('Probplot against normal distribution')\n",
    "prob2 = stats.probplot(df['age_log'], dist=stats.norm, plot=ax2)\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_title('Probplot after log transform')\n",
    "prob3 = stats.probplot(df['age_pt'], dist=stats.norm, plot=ax3)\n",
    "ax3.set_xlabel('Theoretical quantiles')\n",
    "ax3.set_title('Probplot after Yeo-Jhonson transform')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing this, I think is better the Yeo-Jhonson transform. I'll use it.\n",
    "\n",
    "*---*\n",
    "\n",
    "Viendo este gráfico, parece mejor el yeo-jhonson transform. Usaré este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "test['age_pt'] = pt.fit_transform(test[['age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Area and high percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area_percentage_log'] = df['area_percentage'].apply(lambda x : 0 if x<=0 else np.log(x))\n",
    "\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "df['area_percentage_pt'] = pt.fit_transform(df[['area_percentage']])\n",
    "\n",
    "\n",
    "df['height_percentage_log'] = df['height_percentage'].apply(lambda x : 0 if x<=0 else np.log(x))\n",
    "\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "df['height_percentage_pt'] = pt.fit_transform(df[['height_percentage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2, figsize =(15,12))\n",
    "df['area_percentage'].hist(ax=ax[0,0], bins=50)\n",
    "ax[0,0].tick_params(labelsize=10)\n",
    "ax[0,0].set_xlabel('area %', fontsize=10)\n",
    "ax[0,0].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['height_percentage'].hist(ax=ax[0,1], bins=50)\n",
    "ax[0,1].tick_params(labelsize=10)\n",
    "ax[0,1].set_xlabel('hight %', fontsize=10)\n",
    "ax[0,1].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "df['area_percentage_log'].hist(ax=ax[1,0], bins=50)\n",
    "ax[1,0].tick_params(labelsize=10)\n",
    "ax[1,0].set_xlabel('log10(area %))', fontsize=10)\n",
    "ax[1,0].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "\n",
    "df['height_percentage_log'].hist(ax=ax[1,1], bins=50)\n",
    "ax[1,1].tick_params(labelsize=10)\n",
    "ax[1,1].set_xlabel('log10(hight %))', fontsize=10)\n",
    "ax[1,1].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "df['area_percentage_pt'].hist(ax=ax[2,0], bins=50)\n",
    "ax[2,0].tick_params(labelsize=10)\n",
    "ax[2,0].set_xlabel('PowerTransform(area %))', fontsize=10)\n",
    "ax[2,0].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "\n",
    "df['height_percentage_pt'].hist(ax=ax[2,1], bins=50)\n",
    "ax[2,1].tick_params(labelsize=10)\n",
    "ax[2,1].set_xlabel('PowerTransform(hight %))', fontsize=10)\n",
    "ax[2,1].set_ylabel('Occurrence', fontsize=10)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots(3,2, figsize =(15,12))\n",
    "prob1 = stats.probplot(df['area_percentage'], dist=stats.norm, plot=ax[0,0])\n",
    "ax[0,0].set_xlabel('')\n",
    "ax[0,0].set_title('Area Probplot against normal distribution')\n",
    "prob1 = stats.probplot(df['height_percentage'], dist=stats.norm, plot=ax[0,1])\n",
    "ax[0,1].set_xlabel('')\n",
    "ax[0,1].set_title('Height Probplot against normal distribution')\n",
    "\n",
    "\n",
    "prob2 = stats.probplot(df['area_percentage_log'], dist=stats.norm, plot=ax[1,0])\n",
    "ax[1,0].set_xlabel('')\n",
    "ax[1,0].set_title('Area Probplot after log transform')\n",
    "prob2 = stats.probplot(df['height_percentage_log'], dist=stats.norm, plot=ax[1,1])\n",
    "ax[1,1].set_xlabel('')\n",
    "ax[1,1].set_title('Height Probplot after log transform')\n",
    "\n",
    "\n",
    "prob3 = stats.probplot(df['area_percentage_pt'], dist=stats.norm, plot=ax[2,0])\n",
    "ax[2,0].set_xlabel('Theoretical quantiles')\n",
    "ax[2,0].set_title('Area Probplot after Yeo-Jhonson transform')\n",
    "prob3 = stats.probplot(df['height_percentage_pt'], dist=stats.norm, plot=ax[2,1])\n",
    "ax[2,1].set_xlabel('Theoretical quantiles')\n",
    "ax[2,1].set_title('Height Probplot after Yeo-Jhonson transform')\n",
    "\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that yeo-jhonson its better option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "test['area_percentage_pt'] = pt.fit_transform(test[['area_percentage']])\n",
    "pt = PowerTransformer(method= 'yeo-johnson')\n",
    "test['height_percentage_pt'] = pt.fit_transform(test[['height_percentage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we have more than 5% in all categories, then I will only create dummies and i'll drop the x dummy column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(2,5, figsize =(25,10))\n",
    "ax[0,0].hist(df['count_families'])\n",
    "ax[0,0].set_xlabel('count_families', fontsize=10)\n",
    "\n",
    "ax[0,1].hist(df['count_floors_pre_eq'])\n",
    "ax[0,1].set_xlabel('count_floors_pre_eq', fontsize=10)\n",
    "\n",
    "ax[0,2].hist(df['roof_type'])\n",
    "ax[0,2].set_xlabel('roof_type', fontsize=10)\n",
    "\n",
    "ax[0,3].hist(df['position'])\n",
    "ax[0,3].set_xlabel('position', fontsize=10)\n",
    "\n",
    "ax[1,0].hist(df['foundation_type'])\n",
    "ax[1,0].set_xlabel('foundation_type', fontsize=10)\n",
    "\n",
    "ax[1,1].hist(df['ground_floor_type'])\n",
    "ax[1,1].set_xlabel('ground_floor_type', fontsize=10)\n",
    "\n",
    "ax[1,2].hist(df['land_surface_condition'])\n",
    "ax[1,2].set_xlabel('land_surface_condition', fontsize=10)\n",
    "\n",
    "ax[1,3].hist(df['other_floor_type'])\n",
    "ax[1,3].set_xlabel('other_floor_type', fontsize=10)\n",
    "\n",
    "ax[0,4].hist(df['legal_ownership_status'])\n",
    "ax[0,4].set_xlabel('legal_ownership_status', fontsize=10)\n",
    "\n",
    "ax[1,4].hist(df['plan_configuration'])\n",
    "ax[1,4].set_xlabel('plan_configuration', fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_families'] = df['count_families'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "df['count_floors_pre_eq'] = df['count_floors_pre_eq'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "\n",
    "df['position'] = df['position'].apply(lambda x: 'j' if x == 'o' else x)\n",
    "df['legal_ownership_status'] = df['legal_ownership_status'].apply(lambda x: str(1) if x == 'v' else str(0))\n",
    "\n",
    "df['foundation_type'] = df['foundation_type'].apply(lambda x: str(1) if x == 'r' else str(0))\n",
    "df['ground_floor_type'] = df['ground_floor_type'].apply(lambda x: str(1) if x == 'f' else str(0))\n",
    "\n",
    "df['plan_configuration'] = df['plan_configuration'].apply(lambda x : str(1) if x=='d' else str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['count_families'] = test['count_families'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "test['count_floors_pre_eq'] = test['count_floors_pre_eq'].apply(lambda x: str(x) if x <3 else '+3')\n",
    "\n",
    "test['position'] = test['position'].apply(lambda x: 'j' if x == 'o' else x)\n",
    "test['legal_ownership_status'] = test['legal_ownership_status'].apply(lambda x: str(1) if x == 'v' else str(0))\n",
    "\n",
    "test['foundation_type'] = test['foundation_type'].apply(lambda x: str(1) if x == 'r' else str(0))\n",
    "test['ground_floor_type'] = test['ground_floor_type'].apply(lambda x: str(1) if x == 'f' else str(0))\n",
    "\n",
    "test['plan_configuration'] = test['plan_configuration'].apply(lambda x : str(1) if x=='d' else str(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to solve the outliers problem without drop this rows. The steps that I'm going to follow are:\n",
    "    - Use power tranformers like (Box-Cox).\n",
    "    - Re-category poorly represented groups.\n",
    "    - Change kluster number.\n",
    "    - Use robust-scaler.\n",
    "  \n",
    "*-----*\n",
    "\n",
    "Vamos a tratar de resolver el problema de los outliers sin eliminar las filas. Los pasos a seguir serán:\n",
    "    - Usar power transformer como Box.Cox.\n",
    "    - Re-categorizar los grupos mal representados.\n",
    "    - Cambiar número de clusters. \n",
    "    - Usar robus scaler (o min-max scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'damage_grade' \n",
    "numeric = ['age_pt','area_percentage_pt', 'height_percentage_pt','prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3', 'CntFloorAge' , 'CntFloorsArea' , 'CntFloorsHeight' , 'AreaPerAge' , 'HeightPerAge' , 'AreaPerHeight' , 'CntFamFloors' ,  'CntFamArea' ,  'CntFamHeight']\n",
    "dummies = ['count_families_0','count_families_1','count_families_2',\n",
    "                'count_floors_pre_eq_1','count_floors_pre_eq_2',\n",
    "                'foundation_type_1', 'ground_floor_type_1',\n",
    "                'land_surface_condition_t','land_surface_condition_n',\n",
    "                'other_floor_type_j','other_floor_type_q', 'other_floor_type_x', \n",
    "                'position_s','position_t',\n",
    "                'roof_type_n','roof_type_q']\n",
    "\n",
    "binary= ['has_secondary_use','has_secondary_use_agriculture','has_secondary_use_gov_office','has_secondary_use_health_post','has_secondary_use_hotel',\n",
    "    'has_secondary_use_industry','has_secondary_use_institution','has_secondary_use_other','has_secondary_use_rental',\n",
    "    'has_secondary_use_school','has_secondary_use_use_police','has_superstructure_adobe_mud','has_superstructure_bamboo','has_superstructure_cement_mortar_brick',\n",
    "    'has_superstructure_cement_mortar_stone','has_superstructure_mud_mortar_brick','has_superstructure_mud_mortar_stone','has_superstructure_other','has_superstructure_rc_engineered',\n",
    "    'has_superstructure_rc_non_engineered','has_superstructure_stone_flag','has_superstructure_timber','legal_ownership_status_1' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in binary:\n",
    "    sns.catplot(data = df, x = b , hue = target , kind= 'count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = ['has_secondary_use',\n",
    "        'has_secondary_use_agriculture',\n",
    "        'has_superstructure_adobe_mud',\n",
    "        'has_superstructure_cement_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_stone',\n",
    "        'has_superstructure_timber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[target ]+ numeric + dummies + binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[ ['building_id'] +numeric + dummies + binary] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint\n",
    "#df.to_csv(\"../data/trainProb.csv\", index = False)\n",
    "#test.to_csv(\"../data/testProb.csv\", index = False)\n",
    "\n",
    "df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "test = pd.read_csv(\"../data/testProb.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "test[numeric] = KNNImputer(n_neighbors = 12).fit_transform(test[numeric])\n",
    "df[numeric] = KNNImputer(n_neighbors = 12).fit_transform(df[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_train = df[numeric+ [target]]\n",
    "clus_test = test[numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClus = range(2, 14, 2)\n",
    "\n",
    "kmeans = [KMeansFeaturizer(k=i, target_scale =0.3, random_state= 1995) for i in nClus]\n",
    "scaler = RobustScaler()\n",
    "\n",
    "score = [kmeans[i].fit(clus_train.drop(target, axis =1), clus_train[target] ).score for i in range(len(kmeans))]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(nClus,score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSca = range(2, 10, 1)\n",
    "\n",
    "kmeans = [KMeansFeaturizer(k=10, target_scale =i/10, random_state= 1995) for i in tSca]\n",
    "scaler = RobustScaler()\n",
    "\n",
    "score = [kmeans[i].fit(clus_train.drop(target, axis =1), clus_train[target] ).score for i in range(len(kmeans))]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(tSca,score)\n",
    "plt.xlabel('Tar Scale')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSca = range(2, 10, 1)\n",
    "nClus = range(2, 14, 2)\n",
    "\n",
    "fig , ax = plt.subplots(2,3, figsize =(20,20))\n",
    "cont = 0\n",
    "for c in nClus:\n",
    "    kmeans = [KMeansFeaturizer(k=c, target_scale =i/10, random_state= 1995) for i in tSca]\n",
    "\n",
    "    score = [kmeans[i].fit(clus_train.drop(target, axis =1), clus_train[target] ).score for i in range(len(kmeans))]\n",
    "\n",
    "    ax[cont%2,cont%3].plot(tSca,score)\n",
    "    ax[cont%2,cont%3].set_title(f'Tar Scale for {c}-clusters')\n",
    "    cont +=1\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeansFeaturizer(k=12, target_scale =0.5, random_state= 1995)\n",
    "\n",
    "km.fit(clus_train[numeric], clus_train[target])\n",
    "\n",
    "clus_train = km.transform(clus_train[numeric])\n",
    "clus_test = km.transform(clus_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_train = [clus_train[i][0] for i in range(len(clus_train))]\n",
    "clus_test = [clus_test[i][0] for i in range(len(clus_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters'] = clus_train\n",
    "test['clusters'] = clus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Para train tenemos : {df.shape}, y para test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters'] = df['clusters'].apply(lambda x: str(x))\n",
    "test['clusters'] = df['clusters'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second models: Evaluating and comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint\n",
    "#df.to_csv(\"../data/trainProb.csv\", index = False)\n",
    "#test.to_csv(\"../data/testProb.csv\", index = False)\n",
    "\n",
    "df = pd.read_csv(\"../data/trainProb.csv\")\n",
    "test = pd.read_csv(\"../data/testProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'damage_grade' \n",
    "numeric = ['age_pt','area_percentage_pt', 'height_percentage_pt','prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']\n",
    "dummies = ['count_families_0','count_families_1','count_families_2',\n",
    "                'count_floors_pre_eq_1','count_floors_pre_eq_2',\n",
    "                'foundation_type_1', 'ground_floor_type_1',\n",
    "                'land_surface_condition_t','land_surface_condition_n',\n",
    "                'other_floor_type_j','other_floor_type_q', 'other_floor_type_x', \n",
    "                'position_s','position_t',\n",
    "                'roof_type_n','roof_type_q','clusters_0', 'clusters_1', 'clusters_10', 'clusters_11', 'clusters_2',\n",
    "                'clusters_3', 'clusters_4', 'clusters_5', 'clusters_6', 'clusters_7',\n",
    "                'clusters_8', 'clusters_9']\n",
    "\n",
    "binary = ['has_secondary_use',\n",
    "        'has_secondary_use_agriculture',\n",
    "        'has_superstructure_adobe_mud',\n",
    "        'has_superstructure_cement_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_brick',\n",
    "        'has_superstructure_mud_mortar_stone',\n",
    "        'has_superstructure_timber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = [target]), df[target],random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(df.drop(columns = [target,'prob1_geo1','prob1_geo2','prob1_geo3','prob2_geo1','prob2_geo2','prob2_geo3','prob3_geo1','prob3_geo2','prob3_geo3']), df[target],random_state = 1995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(df.drop(columns = [target,'clusters_0', 'clusters_1', 'clusters_10', 'clusters_11', 'clusters_2',\n",
    "                'clusters_3', 'clusters_4', 'clusters_5', 'clusters_6', 'clusters_7',\n",
    "                'clusters_8', 'clusters_9']), df[target],random_state = 1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First aproximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1995\n",
    "models = []\n",
    "models.append(('LR'     , LogisticRegression(random_state=seed)))\n",
    "models.append(('LDA'    , LinearDiscriminantAnalysis()))\n",
    "models.append(('RFC'    , RandomForestClassifier(random_state=seed)))\n",
    "models.append(('LGBM'   , LGBMClassifier(random_state=seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with new FE, we are going to try with the best models options that the other FE give us and LR too, because is the most easy to explain.\n",
    "\n",
    "*-----*\n",
    "\n",
    "Ahora con el nuevo FE, vamos a probar la mejores opciones de modelos que el otro FE nos proporcionó y con LR, ya que es la más sencilla de interpretar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "metric = 'f1_micro'\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    cv_results = cross_val_score(model, X1_train, y1_train, cv =5, scoring = metric)\n",
    "\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(f\"{name}-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models:\n",
    "\n",
    "    cv_results = cross_val_score(model, X2_train, y2_train, cv =5, scoring = metric)\n",
    "\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(f\"{name}-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models:\n",
    "\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv =5, scoring = metric)\n",
    "\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "boxplots_algorithms(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots_algorithms(results[4:], names[4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gridLR = {\n",
    "    'penalty' : ['l2','none'],\n",
    "    'C' : [1,0.1,0.01,0.001],\n",
    "    'max_iter' : [100,150,200]\n",
    "}\n",
    "modelLR = LogisticRegression(random_state= 1995)\n",
    "\n",
    "# Grid serach CV \n",
    "# ==============================================================================\n",
    "gridLR = GridSearchCV(\n",
    "        estimator  = modelLR,\n",
    "        param_grid = param_gridLR,\n",
    "        scoring    = 'f1_micro',\n",
    "        n_jobs     =  -1,\n",
    "        cv         = StratifiedKFold(n_splits=5, shuffle=True, random_state=1995), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "gridLR.fit(X = X2_train, y = y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionesLR = gridLR.predict(X = X2_test)\n",
    "\n",
    "f1score0 = f1_score(\n",
    "        y_true  = y2_test,\n",
    "        y_pred  = prediccionesLR,\n",
    "        average = 'micro'\n",
    "    )\n",
    "\n",
    "print(f\"El f1 score de test es: {round(f1score0,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'solver' : ['svd', 'lsqr', 'eigen'] \n",
    "}\n",
    "\n",
    "CVLRmodel = LinearDiscriminantAnalysis()\n",
    "\n",
    "gridLDA = GridSearchCV( estimator = CVLRmodel,\n",
    "                        param_grid = param,\n",
    "                        scoring = 'f1_micro',\n",
    "                        n_jobs = -1,\n",
    "                        refit = True,\n",
    "                        cv = 5,\n",
    "                        verbose = 1,\n",
    "                        return_train_score = True)\n",
    "\n",
    "gridLDA.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionesLDA = gridLDA.predict(X = X_test)\n",
    "\n",
    "f1score0 = f1_score(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = prediccionesLDA,\n",
    "        average = 'micro'\n",
    "    )\n",
    "\n",
    "print(f\"El f1 score de test es: {round(f1score0,4)} con outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain 0.7359 f1 score in drivenData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "# ==============================================================================\n",
    "param_grid = {'n_estimators': [i for i in range(100,5600, 500)] }\n",
    "\n",
    "# Grid serach CV \n",
    "# ==============================================================================\n",
    "gridLGBM = GridSearchCV(\n",
    "        estimator  = LGBMClassifier(n_jobs =-1, \n",
    "                                    early_stopping_round = 10,\n",
    "                                    bagging_fraction = 0.7 ,\n",
    "                                    verbose = 1),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_micro',\n",
    "        cv         = 5,\n",
    "        refit      = True,\n",
    "        n_jobs     = -1,\n",
    "        verbose    = 3,\n",
    "        return_train_score = True)\n",
    "\n",
    "gridLGBM.fit(X = X_train, y = y_train, eval_set = (X_test, y_test))\n",
    "\n",
    "\n",
    "print(gridLGBM.best_estimator_)\n",
    "print(f\"Time fit: {gridLGBM.refit_time_}s\")\n",
    "print(f\"Score:{ gridLGBM.best_score_ }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "# ==============================================================================\n",
    "param_grid = {'max_depth'   : [15,20,25],\n",
    "              'learning_rate' : [0.01,0.005,0.001]\n",
    "             }\n",
    "\n",
    "# Grid serach CV \n",
    "# ==============================================================================\n",
    "gridLGBM = GridSearchCV(\n",
    "        estimator  = LGBMClassifier( n_estimators = 600,\n",
    "                                    n_jobs =-1,  \n",
    "                                    objective='multiclass',\n",
    "                                    random_state=1995,\n",
    "                                    early_stopping_round = 10),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'f1_micro',\n",
    "        cv         = 5,\n",
    "        refit      = True,\n",
    "        n_jobs     = -1,\n",
    "        verbose    = 3,\n",
    "        return_train_score = True)\n",
    "\n",
    "gridLGBM.fit(X = X_train, y = y_train, eval_set = (X_test, y_test))\n",
    "\n",
    "\n",
    "print(gridLGBM.best_estimator_)\n",
    "print(f\"Time fit: {gridLGBM.refit_time_}s\")\n",
    "print(f\"Score:{ gridLGBM.best_score_ }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLGBM = LGBMClassifier(learning_rate=0.01, n_estimators=425, num_leaves=135,objective='multiclass', random_state=1995)\n",
    "modelLGBM.fit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = test.copy()\n",
    "prediccionesLGBM = modelLGBM.predict(test_copy.drop('building_id',axis=1))\n",
    "test_copy['damage_grade'] = prediccionesLGBM\n",
    "test_copy[['building_id','damage_grade']].to_csv(\"../predictions/predLGBMModel6.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5: Choosing best model, version management and reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos dos opciones, elegir la opción con mejor f1 score y por tanto la más capacidad de acierto tiene o podemos optar por la opción más interpretable. Debido a que el f1 score es \"similar\" para ambos modelos y que para un entorno real siempre tenemos que optar por una buena reproducibilidad y explicatividad. Además, tiene que tener un buen performance, ya que tiempos prolongados de ejecución podrían perjudicar la aplicacion en un entorno de producción.\n",
    "\n",
    "Vamos a hacer una breve comparativa de tiempos de entrenamiento y predicción, scores y parámetros básicos para ver ambos modelos en funcionamiento. Y así poder elegir el mejor modelo para un entorno de producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1995\n",
    "lr_model = LogisticRegression(C=0.1, max_iter=200, random_state=seed)\n",
    "lgbm_model = LGBMClassifier(learning_rate=0.01, n_estimators=425, num_leaves=135,objective='multiclass', random_state=seed)\n",
    "#LR\n",
    "a = time.time()\n",
    "lr_model.fit(X_train, y_train)\n",
    "b = time.time()\n",
    "#LGBM\n",
    "c = time.time()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "d = time.time()\n",
    "\n",
    "print(f\"El modelo \\n\\t{lr_model}\\n\\t ha tardado en entrenar: {round(b-a,2)}s \\n- - - - - - - - - - - \\nEl modelo {lgbm_model} ha tardado en entrenar: {round(d-c,2)}s\\n- - - - - - - - - - - \\n\\\n",
    "    Esto significa que el modelo más rápido es {'Regresión logistica' if (b-a) < (d-c) else 'LGBM' }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1995\n",
    "models = []\n",
    "models.append(('LR'     , LogisticRegression(random_state=seed)))\n",
    "models.append(('LR Hy'  , lr_model ))\n",
    "models.append(('LGBM'   , LGBMClassifier(random_state=seed)))\n",
    "models.append(('LGBM Hy', lgbm_model ))\n",
    "\n",
    "X = df.drop(columns = [target])\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=4, n_repeats=4,random_state=seed)\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "metric = 'f1_micro'\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    itera = 0\n",
    "    a = time.time()\n",
    "    result = []\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        c = time.time()\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv = 5 , scoring = metric)\n",
    "        d = time.time()\n",
    "        msg = \"Iteracion_%s: %f (%f)  %fs\" % (itera+1, cv_results.mean(), cv_results.std(), round(d-c,2))\n",
    "        print(msg)\n",
    "\n",
    "        result.append(cv_results)\n",
    "        itera += 1\n",
    "\n",
    "    result = flatten(result)\n",
    "    results.append(result)\n",
    "    b = time.time()\n",
    "    msg = \"\\t %s: %f (%f)  %fs\" % (name, np.array(result).mean(), np.array(result).std(), round(b-a , 2))\n",
    "    print(\"\\t ... \\n Results:\" )\n",
    "    print(msg)\n",
    "    \n",
    "    print(\"\\t - - - - - - - - -\")\n",
    "    names.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots_algorithms(results, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver fácilmente como los modelos que hemos tuneado los hyperparametros tienen un mejor resultado, ya que no solo tienen una mejor puntuación media, si no que además la desviación típica de la puntuación es más baja también. Sin embargo, vemos como al hyperparametrizar el tiempo de entrenamiento ha aumentado considerablemente, algo que podría ser en algunos casos determinante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6: Preparing for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "train = pd.read_csv(\"../data/train_values.csv\")\n",
    "trainTar = pd.read_csv(\"../data/train_labels.csv\")\n",
    "df = train.merge(trainTar , on= \"building_id\" , how= \"left\")\n",
    "\n",
    "#Test\n",
    "test = pd.read_csv(\"../data/test_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = pipeline(df,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7: Deploying to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8: Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Treveil, M. & the Dataiku Team. (2020). Introducing MLOps (1.a ed., Vol. 1). O’Reilly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Zheng, A., & Casari, A. (2018). Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists. O’Reilly Media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Hunter, J., Dale, D., Firing, E., Droettboom, M., & The Matplotlib development team. (2002-2021). Matplotlib. Matplotlib 3.5.1 documentation. \n",
    "    https://matplotlib.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    scikit-learn: machine learning in Python — scikit-learn 1.0.2 documentation. (2021). Scikit-Learn. \n",
    "    https://scikit-learn.org/stable/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Wikipedia contributors. (2021, 12 septiembre). Out-of-bag error. Wikipedia. https://en.wikipedia.org/wiki/Out-of-bag_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (2019). Richter’s Predictor: Modeling Earthquake Damage. DrivenData. https://www.drivendata.org/competitions/57/nepal-earthquake/page/136/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Wikipedia contributors. (2022, 16 enero). Random forest. Wikipedia. https://en.wikipedia.org/wiki/Random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Cross-validation: evaluating estimator performance. (2021). Scikit-Learn. https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GitHub - 21zhouyun/CountMinSketch: A simple python implementation of count min sketch. (2016). GitHub. https://github.com/21zhouyun/CountMinSketch"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de072921dc87486613898b1ef56959cc98c50a630fb49de1898fb32d92a683cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
